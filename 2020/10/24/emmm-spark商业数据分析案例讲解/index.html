<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>emmm-spark商业数据分析案例讲解 | Gorge</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="记录这篇记录为啥以emmm开头呢？哈哈（～～）～因为我的阿里云还有一个月就要到期了。这意味着又是一波放血～～不过对于一个忠实的阿里粉来说，还是用了自己一个月的生活费，又续租了一年。（这东西有点上瘾，用上了就不想放弃了～～哈哈，这是真好用，所以不能对不起这一个月的生活费不是！当然，如果以后真的有机会进了阿里，阿里爸爸会不会给我免费服务的机会呀！😂） Jupyter notebook 阿里云搭建刚说">
<meta property="og:type" content="article">
<meta property="og:title" content="emmm-spark商业数据分析案例讲解">
<meta property="og:url" content="http://yoursite.com/2020/10/24/emmm-spark商业数据分析案例讲解/index.html">
<meta property="og:site_name" content="Gorge">
<meta property="og:description" content="记录这篇记录为啥以emmm开头呢？哈哈（～～）～因为我的阿里云还有一个月就要到期了。这意味着又是一波放血～～不过对于一个忠实的阿里粉来说，还是用了自己一个月的生活费，又续租了一年。（这东西有点上瘾，用上了就不想放弃了～～哈哈，这是真好用，所以不能对不起这一个月的生活费不是！当然，如果以后真的有机会进了阿里，阿里爸爸会不会给我免费服务的机会呀！😂） Jupyter notebook 阿里云搭建刚说">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201021112803503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201021204557992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201023212023388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201023212642926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201023212832651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201024111407659.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201024112306697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:updated_time" content="2020-10-24T03:43:13.007Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="emmm-spark商业数据分析案例讲解">
<meta name="twitter:description" content="记录这篇记录为啥以emmm开头呢？哈哈（～～）～因为我的阿里云还有一个月就要到期了。这意味着又是一波放血～～不过对于一个忠实的阿里粉来说，还是用了自己一个月的生活费，又续租了一年。（这东西有点上瘾，用上了就不想放弃了～～哈哈，这是真好用，所以不能对不起这一个月的生活费不是！当然，如果以后真的有机会进了阿里，阿里爸爸会不会给我免费服务的机会呀！😂） Jupyter notebook 阿里云搭建刚说">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20201021112803503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center">
  
    <link rel="alternative" href="/atom.xml" title="Gorge" type="application/atom+xml">
  
  
    <link rel="icon" href="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
      <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("your app_id", "your app_key");</script>
<script src="/js/Counter.js"></script>
  
</head></html>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="../../photo/head.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">He Zhang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">欢迎呀</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="https://me.csdn.net/qq_39536716">CSDN</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="zhihu" target="_blank" href="/1660047480" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="/1660047480@qq.com" title="mail">mail</a>
					        
								<a class="qq" target="_blank" href="/1660047480@qq.com" title="qq">qq</a>
					        
								<a class="weibo" target="_blank" href="/1660047480@qq.com" title="weibo">weibo</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/smackgg/hexo-theme-smackdown">smackdown</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">He Zhang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="../../photo/head.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">He Zhang</h1>
			</hgroup>
			
			<p class="header-subtitle">欢迎呀</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="https://me.csdn.net/qq_39536716">CSDN</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="zhihu" target="_blank" href="/1660047480" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="/1660047480@qq.com" title="mail">mail</a>
			        
						<a class="qq" target="_blank" href="/1660047480@qq.com" title="qq">qq</a>
			        
						<a class="weibo" target="_blank" href="/1660047480@qq.com" title="weibo">weibo</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-emmm-spark商业数据分析案例讲解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/24/emmm-spark商业数据分析案例讲解/" class="article-date">
  	<time datetime="2020-10-24T03:29:10.250Z" itemprop="datePublished">2020-10-24</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      emmm-spark商业数据分析案例讲解
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
        

        
          
<div class="counter-tag counter">
    <span id="/2020/10/24/emmm-spark商业数据分析案例讲解/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="emmm-spark商业数据分析案例讲解">
         &nbsp;
        view
    </span>
</div>

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h2><p>这篇记录为啥以emmm开头呢？哈哈（～～）～因为我的阿里云还有一个月就要到期了。这意味着又是一波放血～～不过对于一个忠实的阿里粉来说，还是用了自己一个月的生活费，又续租了一年。（这东西有点上瘾，用上了就不想放弃了～～哈哈，这是真好用，所以不能对不起这一个月的生活费不是！当然，如果以后真的有机会进了阿里，阿里爸爸会不会给我免费服务的机会呀！😂）</p>
<h2 id="Jupyter-notebook-阿里云搭建"><a href="#Jupyter-notebook-阿里云搭建" class="headerlink" title="Jupyter notebook 阿里云搭建"></a>Jupyter notebook 阿里云搭建</h2><p>刚说完，要充分利用，那就赶快利用起来吧！ 本来是搭建在我MAC上的，现在就把它迁移到阿里云上吧！也能让我随时随地的进行编程了～～</p>
<p>名称 Jupyter 是由Julia、Python和R三个单词组合而成的。Jupyter Notebook是一种Web应用，它能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中，非常方便研究和教学。Jupyter Notebook特别适合做数据处理，其用途可以包括数据清理和探索、可视化、机器学习和大数据分析。</p>
<h2 id="服务原理"><a href="#服务原理" class="headerlink" title="服务原理"></a>服务原理</h2><p><img src="https://img-blog.csdnimg.cn/20201021112803503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p>Anaconda是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。Anaconda中已经集成了Jupyter Notebook，因此，可以首先安装Anaconda，然后再配置Jupyter Notebook。</p>
<p>Anaconda的安装过程，这里就不在记录了！</p>
<p>安装好Anaconda之后，检查里面是否已经集成了jupyter Notebook。一般这里面都是集成了的，如果没有的话，那就在安装一下吧！<br>因为我搭建在了云上，这里的安全性还是要保护一下的。因为我的目的是随时随地，随机都可以进行编程！</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/anaconda3/bin</span><br><span class="line">./python</span><br></pre></td></tr></table></figure>
<p>这里来生成一下密码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">&gt;&gt;&gt;passwd()</span><br></pre></td></tr></table></figure></p>
<p>然后系统会生成一个密码字符串，比如sha1；记得将这个密码串保存下来，用来配置你的密码。</p>
<p>退出python之后，找到配置文件。<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip=<span class="string">'*'</span>                     <span class="comment"># 就是设置所有ip皆可访问  </span></span><br><span class="line">c.NotebookApp.password = <span class="string">'sha1:7c7990750e83:965c1466a4fab0849051ca5f3c5661110813795b'</span>     <span class="comment"># 上面复制的那个sha密文'  </span></span><br><span class="line">c.NotebookApp.open_browser = False       <span class="comment"># 禁止自动打开浏览器  </span></span><br><span class="line">c.NotebookApp.port =8888                 <span class="comment"># 端口</span></span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">'/home/hadoop/jupyternotebook'</span>  <span class="comment">#设置Notebook启动进入的目录</span></span><br></pre></td></tr></table></figure>
<p>配置完成之后，使用jupyter notebook启动即可！这时候在本机访问是没有问题的，如果想要通过其他电脑访问还需要进行下一步的策略！</p>
<h2 id="教训"><a href="#教训" class="headerlink" title="教训"></a>教训</h2><p>还记得HDFS实验中，有一个问题没有解决吗？哈哈哈 其实有点傻了。<br>在配置notebook的时候，我使用的是8888端口，阿里云是对这些端口进行保护了的。主要有两层保护：第一层是阿里云本身的防火墙，第二层是控制台的安全组规则。这个经验本来是在mysql的配置的时候解决过的！但是忘记了。所以在执行HDFS分布式文件读取的时候，一直没有成功！但是这里配置的时候，忽然想起了这个事情，所以就把这个问题解决了。HDFS 使用本机用户分布式读取也没问题了。但是写权限还是不够的。</p>
<h2 id="案例讲解"><a href="#案例讲解" class="headerlink" title="案例讲解"></a>案例讲解</h2><p>数据来源：<a href="https://www.kaggle.com/yelp-dataset/yelp-dataset" target="_blank" rel="noopener">YELP数据集</a><strong>仅用来学习</strong> </p>
<h3 id="json-数据集"><a href="#json-数据集" class="headerlink" title="json 数据集"></a>json 数据集</h3><p>这里的数据集格式是属于NoSQL的中的文档数据集格式之一的json数据集格式。<br>因为，这也是我第一次对这类数据进行处理，这里做一个简单的学习记录。</p>
<ol>
<li><p>简介<br>JSON:一种与开发语言无关的、轻量级的数据存储格式，全称JavaScript Object Notation，一种数据格式的标准规范，起初来源于JavaScript这门语言，后来随着使用的广泛，几乎每门开发语言都有处理JSON的API。<br><strong>优点：易于人的阅读和编写，易于程序解析与生产。</strong>（看了一下真的是便于阅读与处理）</p>
<p>JSON样例：首先一个花括号{}，整个代表一个对象，同时里面是一种Key-Value的存储形式，它还有不同的数据类型来区分。</p>
</li>
<li><p>数据类型表示<br>数据结构：Object、Array<br>基本类型：string，number，true，false，null<br>（1）Object<br>{key:value,key:value…}<br>key：string类型<br>value：任何基本类型或数据结构<br>（2）Array<br>[value,value…]<br>value：任何基本类型或数据结构。<br>比如：{“name”:”李广”, “values”:[1,2,45,”你好”] }</p>
</li>
<li><p>实际json数据格式<br>这个格式的文件可以通过t x t或者网页等方式打开，当然还有许多工具。<br>我这里用的是Xcode。好了这就是我们要处理的数据了。<br><img src="https://img-blog.csdnimg.cn/20201021204557992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p>数据集提前分析<br>我这里取出来一条信息，先来看看信息是啥样子的。</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"business_id"</span>:<span class="string">"f9NumwFMBDn751xgFiRbNA"</span>,</span><br><span class="line">        <span class="string">"name"</span>:<span class="string">"The Range At Lake Norman"</span>,</span><br><span class="line">  <span class="string">"address"</span>:<span class="string">"10913 Bailey Rd"</span>,</span><br><span class="line"> <span class="string">"city"</span>:<span class="string">"Cornelius"</span>,</span><br><span class="line"> <span class="string">"state"</span>:<span class="string">"NC"</span>,</span><br><span class="line"> <span class="string">"postal_code"</span>:<span class="string">"28031"</span>,</span><br><span class="line"> <span class="string">"latitude"</span>:35.4627242,</span><br><span class="line"> <span class="string">"longitude"</span>:-80.8526119,</span><br><span class="line"> <span class="string">"stars"</span>:3.5,</span><br><span class="line"> <span class="string">"review_count"</span>:36,</span><br><span class="line"> <span class="string">"is_open"</span>:1,</span><br><span class="line"> <span class="string">"attributes"</span>:&#123;<span class="string">"BusinessAcceptsCreditCards"</span>:<span class="string">"True"</span>,<span class="string">"BikeParking"</span>:<span class="string">"True"</span>,<span class="string">"GoodForKids"</span>:<span class="string">"False"</span>,<span class="string">"BusinessParking"</span>:<span class="string">"&#123;'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False&#125;"</span>,<span class="string">"ByAppointmentOnly"</span>:<span class="string">"False"</span>,<span class="string">"RestaurantsPriceRange2"</span>:<span class="string">"3"</span>&#125;,</span><br><span class="line"> <span class="string">"categories"</span>:<span class="string">"Active Life, Gun\/Rifle Ranges, Guns &amp; Ammo, Shopping"</span>,</span><br><span class="line"> <span class="string">"hours"</span>:&#123;<span class="string">"Monday"</span>:<span class="string">"10:0-18:0"</span>,</span><br><span class="line"> <span class="string">"Tuesday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Wednesday"</span>:<span class="string">"10:0-18:0"</span>,</span><br><span class="line"> <span class="string">"Thursday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Friday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Saturday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Sunday"</span>:<span class="string">"13:0-18:0"</span>&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>上面描述的就是这个文档中所有数据集中其中的一条数据。<br>可以发现json数据格式是按照键值对的形式进行存储的。</p>
<ul>
<li>business_id ： 商业店铺的id,用来唯一的标识这一个商铺</li>
<li>name : 商业店铺的名称</li>
<li>address : 商铺的位置</li>
<li>city : 城镇</li>
<li>state : 州县</li>
<li>postal_code : 邮政编码</li>
<li>latitude :纬度</li>
<li>longitude :经度</li>
<li>starts : 星级评分</li>
<li>review_count：评论数</li>
<li>is_open： 商家是否营业</li>
<li>attributes ：商家所进行的业务</li>
<li>categories: 类别</li>
<li>hours : 商家的营业时间</li>
</ul>
<h3 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h3><ol>
<li>统计出所有的商业类别，并且进行计算出商业类别的Top 10(categories)。</li>
<li>每个城市各种商业类型的商家数量,并且计算出商家数量最多的十个城市(city,categories)。</li>
<li>消费者评价最多的10种商业类别(review_count,categories)。</li>
<li>最受消费者欢迎的10种商业类别(starts)。</li>
<li>商业额外业务的评价情况。</li>
</ol>
<h3 id="主要的解决步骤"><a href="#主要的解决步骤" class="headerlink" title="主要的解决步骤"></a>主要的解决步骤</h3><ol>
<li>第一步 对数据进行预处理，剔除异常值</li>
<li>第二步 进行数据集的分析</li>
<li>第三步 对数据进行可视化分析</li>
</ol>
<h2 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h2><h3 id="所需要的包"><a href="#所需要的包" class="headerlink" title="所需要的包"></a>所需要的包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf,SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> f</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<ul>
<li><p>pyspark<br>PySpark 是 Spark 为 Python 开发者提供的 API</p>
<ul>
<li>SparkContext<br>是程序的入口点，负责连接Spark集群。集群通过SparkContext进行资源管理器的通信以及进行资源的申请、任务的分配和监控，需要从SparkSession中获得</li>
<li>SparkConf<br>创建SparkContext前得使用SparkConf进行配置，以键值对形式进行</li>
</ul>
</li>
<li><p>pyspark.sql<br>一种解析传统SQL到大数据运算模型的引擎</p>
<ul>
<li>SparkSession<br>其为用户提供了一个统一的切入点来使用Spark的各项功能，并且允许用户通过它调用DataFrame和Dataset相关API来编写Spark程序</li>
<li>DataFrame（表）是Spark SQL对结构化数据的抽象。可以将DataFrame看做RDD</li>
<li>Dataset是数据的分布式集合</li>
</ul>
</li>
<li>pyspark.sql.function<br>可用于dataFram的内置功能列表</li>
<li>os<br>主要是针对操作系统的包，用来与操作系统进行交互，创建文件等。</li>
<li>json<br>Python里的json模块主要用于“Python数据与JSON格式的数据间相互转换”</li>
<li>pandas<br>pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。</li>
<li>matplotlib.pyplot<br>是matlib的python版实现，用于绘图操作。</li>
</ul>
<h3 id="获取spark操作对象"><a href="#获取spark操作对象" class="headerlink" title="获取spark操作对象"></a>获取spark操作对象</h3><p>建立一个会话对象<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立配置文件</span></span><br><span class="line"><span class="comment">#builder用来创建一个Sparksession实例</span></span><br><span class="line"><span class="comment">#config 配置相关</span></span><br><span class="line"><span class="comment">#getOrCreate 有就获取没有就创建</span></span><br><span class="line">spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()</span><br></pre></td></tr></table></figure></p>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>下面对数据清洗 进行一个详细的分析。主要将数据中存在值缺失的数据，商家位置错误的数据（这里可以称为离群值）进行筛选。代码的详解解读，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据清洗</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_process</span><span class="params">(raw_data_path)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 通过数据路径，读取数据，这里是json数据</span></span><br><span class="line">    business = spark.read.json(raw_data_path)</span><br><span class="line">    <span class="comment">#split(str, pattern, limit=-1)</span></span><br><span class="line">    <span class="comment">#str – 我们要分割的字符串</span></span><br><span class="line">    <span class="comment">#pattern 分割所用的正则表达式</span></span><br><span class="line">    split_col = f.split(business[<span class="string">'categories'</span>], <span class="string">','</span>)</span><br><span class="line">    <span class="comment">#withColumn(colName, col)</span></span><br><span class="line">    <span class="comment">#withColumn 负责在原有表的基础上新添加一列 colName是添加一列后的新的列名，col是新列的值 ？列名一样会怎么样处理（这里应该是会直接替代原来的，有待验证）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#filter 使用给定的条件 过滤行 这里是在所有的categories中过滤掉城市</span></span><br><span class="line">    <span class="comment"># dropna 至少又一个空缺值的行都会被删除</span></span><br><span class="line">    business = business.withColumn(<span class="string">"categories"</span>, split_col).filter(business[<span class="string">"city"</span>] != <span class="string">""</span>).dropna()</span><br><span class="line">    <span class="comment">#创建一个数据的临时视图，这个视图的周期与sparkSession相关联</span></span><br><span class="line">    business.createOrReplaceTempView(<span class="string">"business"</span>)</span><br><span class="line">    <span class="comment">#解析传统的sql到大数据运算模型 筛选出所需要的内容</span></span><br><span class="line">    <span class="comment">#cache 按照默认的存储级别 持久化dataFrame</span></span><br><span class="line">    b_etl = spark.sql(<span class="string">"SELECT business_id, name, city, state, latitude, longitude, stars, review_count, is_open, categories, attributes FROM business"</span>).cache()</span><br><span class="line">    <span class="comment">#将筛选完的数据 在进行一个临时视图 方便下一步的sql分析</span></span><br><span class="line">    b_etl.createOrReplaceTempView(<span class="string">"b_etl"</span>)</span><br><span class="line">    <span class="comment">#这里是筛选掉 离群值 （距离洲内商家平均位置的欧式距离）</span></span><br><span class="line">    <span class="comment">#b1 作为business的原始数据表 b2是在原始数据表的基础上计算每个州县的平均 经纬度 然后计算每一个商家在这个州县的欧式距离 并根据计算结果降序排列</span></span><br><span class="line">    outlier = spark.sql(</span><br><span class="line">        <span class="string">"SELECT b1.business_id, SQRT(POWER(b1.latitude - b2.avg_lat, 2) + POWER(b1.longitude - b2.avg_long, 2)) \</span></span><br><span class="line"><span class="string">        as dist FROM b_etl b1 INNER JOIN (SELECT state, AVG(latitude) as avg_lat, AVG(longitude) as avg_long \</span></span><br><span class="line"><span class="string">        FROM b_etl GROUP BY state) b2 ON b1.state = b2.state ORDER BY dist DESC"</span>)</span><br><span class="line">    <span class="comment">#创建一个新的临时视图 outlier</span></span><br><span class="line">    outlier.createOrReplaceTempView(<span class="string">"outlier"</span>)</span><br><span class="line">    <span class="comment">#从b_et1中 筛选出所有的距离小于10 的值。这对应到经纬度上面 已经是比较大的值了</span></span><br><span class="line">    joined = spark.sql(<span class="string">"SELECT b.* FROM b_etl b INNER JOIN outlier o ON b.business_id = o.business_id WHERE o.dist&lt;10"</span>)</span><br><span class="line">    <span class="comment">#将筛选后的数据进行存储 存储为parquet的格式</span></span><br><span class="line">    joined.write.parquet(<span class="string">"file:///home/hadoop/yelp-etl/business_etl"</span>, mode=<span class="string">"overwrite"</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="内容补充"><a href="#内容补充" class="headerlink" title="内容补充"></a>内容补充</h4><ol>
<li>parquet 文件格式<br>parquet采用不同的压缩比，能达到有效的压缩比。减少磁盘的使用。<br>parquet结合spark，可以完美的实现支持分区过滤。如，需要某个产品某段时间的数据，则hdfs只取这个文件夹。<br>列修剪：其实说简单点就是我们要取回的那些列的数据</li>
<li>离群值<br>离群值(outlier)，也称逸出值，是指在数据中有一个或几个数值与其他数值相比差异较大.</li>
<li>withColumn(colName, col)<br>  这里要解决的问题是，我们在项目中遗留的一个问题，withColumn往数据里面执行添加操作的时候，当colName的名字与原表中的名字一样的时候，添加操作是如何进行的。</li>
</ol>
<h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><p>这一部分主要对清理后的数据进行分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analysis</span><span class="params">(data_path)</span>:</span></span><br><span class="line">    <span class="comment"># 读取清理后的数据路径，存储的parque数据，并持久化到磁盘中</span></span><br><span class="line">    business = spark.read.parquet(data_path).cache()</span><br><span class="line">    <span class="comment">#将新的数据建立一个新的视图 business</span></span><br><span class="line">    business.createOrReplaceTempView(<span class="string">"business"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#从上面处理过的数据中，选择各种商业类别的洲县、城镇、星级评分、评论数</span></span><br><span class="line">    <span class="comment">#explode 在sql语句中用来处理array类型的数据。</span></span><br><span class="line">    part_business = spark.sql(<span class="string">"SELECT state, city, stars,review_count, explode(categories) AS category FROM business"</span>).cache()</span><br><span class="line">    <span class="comment">#默认显示前 20 行 并提示only showing top 20 rows</span></span><br><span class="line">    part_business.show()</span><br></pre></td></tr></table></figure>
<p>Start analysis data!<br>+—–+—————-+—–+————+——————–+<br>|state|            city|stars|review_count|            category|<br>+—–+—————-+—–+————+——————–+<br>|   AZ|         Phoenix|  4.0|          41|            Notaries|<br>|   AZ|         Phoenix|  4.0|          41|     Mailbox Centers|<br>|   AZ|         Phoenix|  4.0|          41|   Printing Services|<br>|   AZ|         Phoenix|  4.0|          41|      Local Services|<br>|   AZ|         Phoenix|  4.0|          41|    Shipping Centers|<br>|   NV|       Las Vegas|  4.0|         681|         Restaurants|<br>|   NV|       Las Vegas|  4.0|         681|                Bars|<br>|   NV|       Las Vegas|  4.0|         681|           Nightlife|<br>|   NV|       Las Vegas|  4.0|         681|      American (New)|<br>|   NV|       Las Vegas|  4.0|         681|             Seafood|<br>|   QC|Vaudreuil-Dorion|  4.0|           7|                Food|<br>|   QC|Vaudreuil-Dorion|  4.0|           7|            Bakeries|<br>|   AZ|      Scottsdale|  3.5|           5|            Shopping|<br>|   AZ|      Scottsdale|  3.5|           5|       Home &amp; Garden|<br>|   AZ|      Scottsdale|  3.5|           5|          Mattresses|<br>|   NC|       Charlotte|  3.0|          64|                Gyms|<br>|   NC|       Charlotte|  3.0|          64|        Sports Clubs|<br>|   NC|       Charlotte|  3.0|          64|         Active Life|<br>|   NC|       Charlotte|  3.0|          64| Fitness &amp; Instru…|<br>|   ON|     Mississauga|  4.5|          12|         Restaurants|<br>+—–+—————-+—–+————+——————–+<br>only showing top 20 rows</p>
<p>上述就是对处理完的数据进行一个显示以及筛选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将筛选的商业类别的相关信息 创建一个新的视图</span></span><br><span class="line">    part_business.createOrReplaceTempView(<span class="string">'part_business_1'</span>)</span><br><span class="line">    <span class="comment">#选择洲 城市 星级评定，评论数 </span></span><br><span class="line">    <span class="comment">#  REPLACE(category, ' ','')as new_category 的含义是对category 这一行进行‘’ 替换成‘’ 然后创建一个新的代表商家类别的列（相当于对这一列的数据进行了一个备份）</span></span><br><span class="line">    part_business = spark.sql(<span class="string">"SELECT state, city, stars, review_count, REPLACE(category, ' ','')as new_category FROM part_business_1"</span>)</span><br><span class="line">    <span class="comment"># 创建一个新的视图</span></span><br><span class="line">    part_business.createOrReplaceTempView(<span class="string">'part_business'</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 所有的不同的商家类别</span></span><br><span class="line">    print(<span class="string">"## All distinct categories"</span>)</span><br><span class="line">    <span class="comment"># 筛选所有种类的商家 分别是商家的id 以及 商家的种类</span></span><br><span class="line">    all_categories = spark.sql(<span class="string">"SELECT business_id, explode(categories) AS category FROM business"</span>)</span><br><span class="line">    <span class="comment">#将筛选出的数据重新创建一个新的视图</span></span><br><span class="line">    all_categories.createOrReplaceTempView(<span class="string">'all_categories'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 祛除重复的数据 并计算出所有种类的个数</span></span><br><span class="line">    distinct = spark.sql(<span class="string">"SELECT COUNT(DISTINCT(new_category)) FROM part_business"</span>)</span><br><span class="line">    distinct.show()</span><br></pre></td></tr></table></figure>
<p>上述过程是统计出所有种类的商家。</p>
<p> All distinct categories<br>+—————————-+<br>|count(DISTINCT new_category)|<br>+—————————-+<br>|                        1318|<br>+—————————-+</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"## Top 10 business categories"</span>)</span><br><span class="line">    <span class="comment">#统计出没种种类的商家的个数 并且按照降序排列</span></span><br><span class="line">    top_cat = spark.sql(<span class="string">"SELECT new_category, COUNT(*) as freq FROM part_business GROUP BY new_category ORDER BY freq DESC"</span>)</span><br><span class="line">    <span class="comment">#显示出排名前10的商家的种类</span></span><br><span class="line">    top_cat.show(<span class="number">10</span>) </span><br><span class="line">    <span class="comment">#将统计出的数据 存储为 json文件</span></span><br><span class="line">    top_cat.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/top_category"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201023212023388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在每个城市中商业种类的个数 仅按照商业种类的个数显示 前20条 </span></span><br><span class="line">   print(<span class="string">"## Top business categories - in every city"</span>)</span><br><span class="line">   top_cat_city = spark.sql(<span class="string">"SELECT city, new_category, COUNT(*) as freq FROM part_business GROUP BY city, new_category ORDER BY freq DESC"</span>)</span><br><span class="line">   top_cat_city.show()  </span><br><span class="line">   <span class="comment">#将数据存储到json中</span></span><br><span class="line">   top_cat.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/top_category_city"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 商业数量最多的城市</span></span><br><span class="line">    print(<span class="string">"## Cities with most businesses"</span>)</span><br><span class="line">    bus_city = spark.sql(<span class="string">"SELECT city, COUNT(business_id) as no_of_bus FROM business GROUP BY city ORDER BY no_of_bus DESC"</span>)</span><br><span class="line">    bus_city.show(<span class="number">10</span>)   </span><br><span class="line">    bus_city.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/top_business_city"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201023212642926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#每种商业种类的 平均评论数 </span></span><br><span class="line">    print(<span class="string">"## Average review count by category"</span>)</span><br><span class="line">    avg_city = spark.sql(</span><br><span class="line">        <span class="string">"SELECT new_category, AVG(review_count)as avg_review_count FROM part_business GROUP BY new_category ORDER BY avg_review_count DESC"</span>)</span><br><span class="line">    avg_city.show()  </span><br><span class="line">    avg_city.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/average_review_category"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201023212832651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这里其实也是显示了20行，就不截图太多了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#每种商业类别的 平均星级水平</span></span><br><span class="line">    print(<span class="string">"## Average stars by category"</span>)</span><br><span class="line">    avg_state = spark.sql(</span><br><span class="line">        <span class="string">"SELECT new_category, AVG(stars) as avg_stars FROM part_business GROUP BY new_category ORDER BY avg_stars DESC"</span>)</span><br><span class="line">    avg_state.show()   </span><br><span class="line">    avg_state.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/average_stars_category"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p>由于字段 attribute 中的RestaurantsTakeout可能NULL的情况，所以需要利用dropna()处理缺失值的问题。该项对商家是否有’Take out’服务进行分析，统计出两种不同情况的商家的平均星级评分.对应的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 商家所进行的业务分析</span></span><br><span class="line">    print(<span class="string">"## Data based on Attribute"</span>)</span><br><span class="line">    <span class="comment">#仅筛选出 商家所进行的业务，星级，以及划分到的商业类别</span></span><br><span class="line">    for_att = spark.sql(<span class="string">"SELECT attributes, stars, explode(categories) AS category FROM business"</span>)</span><br><span class="line">    <span class="comment">#将筛选出的数据 创建一个新的视图</span></span><br><span class="line">    for_att.createOrReplaceTempView(<span class="string">"for_att"</span>)</span><br><span class="line">    <span class="comment">#对 商家是否 有外卖这个 业务进行分析</span></span><br><span class="line">    attribute = <span class="string">'RestaurantsTakeout'</span></span><br><span class="line">    attribute_score(attribute)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attribute_score</span><span class="params">(attribute)</span>:</span></span><br><span class="line">    <span class="comment"># 这里的format 表示用attribute的值代替attr的值</span></span><br><span class="line">    att = spark.sql(<span class="string">"SELECT attributes.&#123;attr&#125; as &#123;attr&#125;, category, stars FROM for_att"</span>.format(attr=attribute)).dropna()</span><br><span class="line">    att.createOrReplaceTempView(<span class="string">"att"</span>)</span><br><span class="line">    att_group = spark.sql(<span class="string">"SELECT &#123;attr&#125;, AVG(stars) AS stars FROM att GROUP BY &#123;attr&#125; ORDER BY stars"</span>.format(attr=attribute))</span><br><span class="line">    att_group.show()    </span><br><span class="line">    att_group.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/&#123;attr&#125;"</span>.format(attr=attribute), mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure></p>
<p>到这里所有的数据分析的代码就讲解完了。接下来我们来看一下，对于我们统计出来的这些数据，我们那如何更直观的查看。也就是数据的可视化</p>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><p>这里我们进行的数据可视化是通过 python中的matlib包进行绘图表示的。</p>
<h4 id="数据的读取"><a href="#数据的读取" class="headerlink" title="数据的读取"></a>数据的读取</h4><p>我们先将上面已经分析过的数据并存储在磁盘上的数据路径自定义。（这一块系统可是无法自己找到）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">AVE_REVIEW_CATEGORY = <span class="string">'/usr/local/spark/yelp/analysis/average_review_category'</span></span><br><span class="line">TOP_CATEGORY_CITY = <span class="string">'/usr/local/spark/yelp/analysis/top_category_city'</span></span><br><span class="line">TOP_BUSINESS_CITY = <span class="string">'/usr/local/spark/yelp/analysis/top_business_city'</span></span><br><span class="line">TOP_CATEGORY = <span class="string">'/usr/local/spark/yelp/analysis/top_category'</span></span><br><span class="line">AVE_STARS_CATEGORY = <span class="string">'/usr/local/spark/yelp/analysis/average_stars_category'</span></span><br><span class="line">TAKEOUT = <span class="string">'/usr/local/spark/yelp/analysis/RestaurantsTakeout'</span></span><br></pre></td></tr></table></figure>
<h4 id="定义数据读取的函数"><a href="#定义数据读取的函数" class="headerlink" title="定义数据读取的函数"></a>定义数据读取的函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_json</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    <span class="comment">#读取这个路径下的所有文件的名称</span></span><br><span class="line">    json_path_names = os.listdir(file_path)</span><br><span class="line">    data = []</span><br><span class="line">    <span class="comment">#遍历所有的文件</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(len(json_path_names)):</span><br><span class="line">        <span class="comment">#拼接路径名称</span></span><br><span class="line">        json_path = file_path + <span class="string">'/'</span> + json_path_names[idx]</span><br><span class="line">        <span class="comment">#判断文件是不是json文件 如果是的话 就打开读取</span></span><br><span class="line">        <span class="keyword">if</span> json_path.endswith(<span class="string">'.json'</span>):</span><br><span class="line">            <span class="keyword">with</span> open(json_path) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="comment">#将读取的数据拼接到data中 返回读取到的数据</span></span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                    data.append(json.loads(line))</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<p>获得读取的所有的数据 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ave_review_category_list = read_json(AVE_REVIEW_CATEGORY)</span><br><span class="line">open_close_list = read_json(OPEN_CLOSE)</span><br><span class="line">top_category_city_list = read_json(TOP_CATEGORY_CITY)</span><br><span class="line">top_business_city_list = read_json(TOP_BUSINESS_CITY)</span><br><span class="line">top_category_list = read_json(TOP_CATEGORY)</span><br><span class="line">ave_stars_category_list = read_json(AVE_STARS_CATEGORY)</span><br><span class="line">takeout_list = read_json(TAKEOUT)</span><br></pre></td></tr></table></figure>
<h4 id="下面是数据的图形化展示"><a href="#下面是数据的图形化展示" class="headerlink" title="下面是数据的图形化展示"></a>下面是数据的图形化展示</h4><p>对于这一部分，对一部分进行讲解，因为其余的图形的绘画 的思路是一样的。不一样的地方，在于画图的语法不一样。（这里可以自行学习）<br><a href="https://matplotlib.org/gallery/index.html" target="_blank" rel="noopener">学习链接（marplotlib画图）</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在每个城市中商业种类的个数 仅按照商业种类的个数显示 前10条 根据商业种类出现的次数进行 排名 从小到大</span></span><br><span class="line">    top_category_list.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">'freq'</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#商业种类的名称</span></span><br><span class="line">    top_category_key = []</span><br><span class="line">    <span class="comment">#商业种类的统计个数</span></span><br><span class="line">    top_category_value = []</span><br><span class="line">    <span class="comment">#数据填充</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        one = top_category_list[idx]</span><br><span class="line">        top_category_key.append(one[<span class="string">'new_category'</span>])</span><br><span class="line">        top_category_value.append(one[<span class="string">'freq'</span>])</span><br><span class="line">    <span class="comment">#绘制条形图 截取前10名</span></span><br><span class="line">    plt.barh(top_category_key[:<span class="number">10</span>], top_category_value[:<span class="number">10</span>], tick_label=top_category_key[:<span class="number">10</span>])</span><br><span class="line">    <span class="comment">#标题</span></span><br><span class="line">    plt.title(<span class="string">'Top 10 Categories'</span>, size = <span class="number">16</span>)</span><br><span class="line">    <span class="comment">#x 的label为Frequency 条形图的宽度为 8 颜色 black</span></span><br><span class="line">    plt.xlabel(<span class="string">'Frequency'</span>,size =<span class="number">8</span>, color = <span class="string">'Black'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Category'</span>,size = <span class="number">8</span>, color = <span class="string">'Black'</span>)</span><br><span class="line">    <span class="comment"># 会自动填充子图参数 让子图能够填充整个图像区域。（仅仅检查 坐标轴的标签，刻度标签以及标题的部分）</span></span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201024111407659.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20201024112306697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这样是不是看起来就更加直观了呢！</p>
<p>显示的图片不是很清晰，或者标题的字体格式等也是可以调的，这里就不在详细的介绍了。</p>
<p>源码就存在我的jupyter上了（不过需要我开启服务器才可以访问）<a href="http://www.itgorge.ltd:8888/notebooks/PYSparkTest.ipynb" target="_blank" rel="noopener">源码</a></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2020/10/16/大数据分析之阿里云安装Spark/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">大数据分析之阿里云安装Spark</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="emmm-spark商业数据分析案例讲解" data-title="emmm-spark商业数据分析案例讲解" data-url="http://yoursite.com/2020/10/24/emmm-spark商业数据分析案例讲解/" data-images="../../photo/head.jpg" data-content="emmm-spark商业数据分析案例讲解">
    <div class="ds-share-inline">
      <ul class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul>
      <div class="ds-share-icons-more">
      </div>
    </div>
 </div>
 





</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2020 Gorge
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>