<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Gorge</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Gorge">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Gorge">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gorge">
  
    <link rel="alternative" href="/atom.xml" title="Gorge" type="application/atom+xml">
  
  
    <link rel="icon" href="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
      <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("your app_id", "your app_key");</script>
<script src="/js/Counter.js"></script>
  
</head></html>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="../../photo/head.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">He Zhang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">欢迎呀</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="https://me.csdn.net/qq_39536716">CSDN</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="zhihu" target="_blank" href="/1660047480" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="/1660047480@qq.com" title="mail">mail</a>
					        
								<a class="qq" target="_blank" href="/1660047480@qq.com" title="qq">qq</a>
					        
								<a class="weibo" target="_blank" href="/1660047480@qq.com" title="weibo">weibo</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/smackgg/hexo-theme-smackdown">smackdown</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">He Zhang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="../../photo/head.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">He Zhang</h1>
			</hgroup>
			
			<p class="header-subtitle">欢迎呀</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="https://me.csdn.net/qq_39536716">CSDN</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="zhihu" target="_blank" href="/1660047480" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="/1660047480@qq.com" title="mail">mail</a>
			        
						<a class="qq" target="_blank" href="/1660047480@qq.com" title="qq">qq</a>
			        
						<a class="weibo" target="_blank" href="/1660047480@qq.com" title="weibo">weibo</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-emmm-spark商业数据分析案例讲解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/24/emmm-spark商业数据分析案例讲解/" class="article-date">
  	<time datetime="2020-10-24T03:29:10.250Z" itemprop="datePublished">2020-10-24</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/24/emmm-spark商业数据分析案例讲解/">
        emmm-spark商业数据分析案例讲解
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h2><p>这篇记录为啥以emmm开头呢？哈哈（～～）～因为我的阿里云还有一个月就要到期了。这意味着又是一波放血～～不过对于一个忠实的阿里粉来说，还是用了自己一个月的生活费，又续租了一年。（这东西有点上瘾，用上了就不想放弃了～～哈哈，这是真好用，所以不能对不起这一个月的生活费不是！当然，如果以后真的有机会进了阿里，阿里爸爸会不会给我免费服务的机会呀！😂）</p>
<h2 id="Jupyter-notebook-阿里云搭建"><a href="#Jupyter-notebook-阿里云搭建" class="headerlink" title="Jupyter notebook 阿里云搭建"></a>Jupyter notebook 阿里云搭建</h2><p>刚说完，要充分利用，那就赶快利用起来吧！ 本来是搭建在我MAC上的，现在就把它迁移到阿里云上吧！也能让我随时随地的进行编程了～～</p>
<p>名称 Jupyter 是由Julia、Python和R三个单词组合而成的。Jupyter Notebook是一种Web应用，它能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中，非常方便研究和教学。Jupyter Notebook特别适合做数据处理，其用途可以包括数据清理和探索、可视化、机器学习和大数据分析。</p>
<h2 id="服务原理"><a href="#服务原理" class="headerlink" title="服务原理"></a>服务原理</h2><p><img src="https://img-blog.csdnimg.cn/20201021112803503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p>Anaconda是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。Anaconda中已经集成了Jupyter Notebook，因此，可以首先安装Anaconda，然后再配置Jupyter Notebook。</p>
<p>Anaconda的安装过程，这里就不在记录了！</p>
<p>安装好Anaconda之后，检查里面是否已经集成了jupyter Notebook。一般这里面都是集成了的，如果没有的话，那就在安装一下吧！<br>因为我搭建在了云上，这里的安全性还是要保护一下的。因为我的目的是随时随地，随机都可以进行编程！</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/hadoop/anaconda3/bin</span><br><span class="line">./python</span><br></pre></td></tr></table></figure>
<p>这里来生成一下密码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">&gt;&gt;&gt;passwd()</span><br></pre></td></tr></table></figure></p>
<p>然后系统会生成一个密码字符串，比如sha1；记得将这个密码串保存下来，用来配置你的密码。</p>
<p>退出python之后，找到配置文件。<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip=<span class="string">'*'</span>                     <span class="comment"># 就是设置所有ip皆可访问  </span></span><br><span class="line">c.NotebookApp.password = <span class="string">'sha1:7c7990750e83:965c1466a4fab0849051ca5f3c5661110813795b'</span>     <span class="comment"># 上面复制的那个sha密文'  </span></span><br><span class="line">c.NotebookApp.open_browser = False       <span class="comment"># 禁止自动打开浏览器  </span></span><br><span class="line">c.NotebookApp.port =8888                 <span class="comment"># 端口</span></span><br><span class="line">c.NotebookApp.notebook_dir = <span class="string">'/home/hadoop/jupyternotebook'</span>  <span class="comment">#设置Notebook启动进入的目录</span></span><br></pre></td></tr></table></figure>
<p>配置完成之后，使用jupyter notebook启动即可！这时候在本机访问是没有问题的，如果想要通过其他电脑访问还需要进行下一步的策略！</p>
<h2 id="教训"><a href="#教训" class="headerlink" title="教训"></a>教训</h2><p>还记得HDFS实验中，有一个问题没有解决吗？哈哈哈 其实有点傻了。<br>在配置notebook的时候，我使用的是8888端口，阿里云是对这些端口进行保护了的。主要有两层保护：第一层是阿里云本身的防火墙，第二层是控制台的安全组规则。这个经验本来是在mysql的配置的时候解决过的！但是忘记了。所以在执行HDFS分布式文件读取的时候，一直没有成功！但是这里配置的时候，忽然想起了这个事情，所以就把这个问题解决了。HDFS 使用本机用户分布式读取也没问题了。但是写权限还是不够的。</p>
<h2 id="案例讲解"><a href="#案例讲解" class="headerlink" title="案例讲解"></a>案例讲解</h2><p>数据来源：<a href="https://www.kaggle.com/yelp-dataset/yelp-dataset" target="_blank" rel="noopener">YELP数据集</a><strong>仅用来学习</strong> </p>
<h3 id="json-数据集"><a href="#json-数据集" class="headerlink" title="json 数据集"></a>json 数据集</h3><p>这里的数据集格式是属于NoSQL的中的文档数据集格式之一的json数据集格式。<br>因为，这也是我第一次对这类数据进行处理，这里做一个简单的学习记录。</p>
<ol>
<li><p>简介<br>JSON:一种与开发语言无关的、轻量级的数据存储格式，全称JavaScript Object Notation，一种数据格式的标准规范，起初来源于JavaScript这门语言，后来随着使用的广泛，几乎每门开发语言都有处理JSON的API。<br><strong>优点：易于人的阅读和编写，易于程序解析与生产。</strong>（看了一下真的是便于阅读与处理）</p>
<p>JSON样例：首先一个花括号{}，整个代表一个对象，同时里面是一种Key-Value的存储形式，它还有不同的数据类型来区分。</p>
</li>
<li><p>数据类型表示<br>数据结构：Object、Array<br>基本类型：string，number，true，false，null<br>（1）Object<br>{key:value,key:value…}<br>key：string类型<br>value：任何基本类型或数据结构<br>（2）Array<br>[value,value…]<br>value：任何基本类型或数据结构。<br>比如：{“name”:”李广”, “values”:[1,2,45,”你好”] }</p>
</li>
<li><p>实际json数据格式<br>这个格式的文件可以通过t x t或者网页等方式打开，当然还有许多工具。<br>我这里用的是Xcode。好了这就是我们要处理的数据了。<br><img src="https://img-blog.csdnimg.cn/20201021204557992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p>数据集提前分析<br>我这里取出来一条信息，先来看看信息是啥样子的。</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"business_id"</span>:<span class="string">"f9NumwFMBDn751xgFiRbNA"</span>,</span><br><span class="line">        <span class="string">"name"</span>:<span class="string">"The Range At Lake Norman"</span>,</span><br><span class="line">  <span class="string">"address"</span>:<span class="string">"10913 Bailey Rd"</span>,</span><br><span class="line"> <span class="string">"city"</span>:<span class="string">"Cornelius"</span>,</span><br><span class="line"> <span class="string">"state"</span>:<span class="string">"NC"</span>,</span><br><span class="line"> <span class="string">"postal_code"</span>:<span class="string">"28031"</span>,</span><br><span class="line"> <span class="string">"latitude"</span>:35.4627242,</span><br><span class="line"> <span class="string">"longitude"</span>:-80.8526119,</span><br><span class="line"> <span class="string">"stars"</span>:3.5,</span><br><span class="line"> <span class="string">"review_count"</span>:36,</span><br><span class="line"> <span class="string">"is_open"</span>:1,</span><br><span class="line"> <span class="string">"attributes"</span>:&#123;<span class="string">"BusinessAcceptsCreditCards"</span>:<span class="string">"True"</span>,<span class="string">"BikeParking"</span>:<span class="string">"True"</span>,<span class="string">"GoodForKids"</span>:<span class="string">"False"</span>,<span class="string">"BusinessParking"</span>:<span class="string">"&#123;'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False&#125;"</span>,<span class="string">"ByAppointmentOnly"</span>:<span class="string">"False"</span>,<span class="string">"RestaurantsPriceRange2"</span>:<span class="string">"3"</span>&#125;,</span><br><span class="line"> <span class="string">"categories"</span>:<span class="string">"Active Life, Gun\/Rifle Ranges, Guns &amp; Ammo, Shopping"</span>,</span><br><span class="line"> <span class="string">"hours"</span>:&#123;<span class="string">"Monday"</span>:<span class="string">"10:0-18:0"</span>,</span><br><span class="line"> <span class="string">"Tuesday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Wednesday"</span>:<span class="string">"10:0-18:0"</span>,</span><br><span class="line"> <span class="string">"Thursday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Friday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Saturday"</span>:<span class="string">"11:0-20:0"</span>,</span><br><span class="line"> <span class="string">"Sunday"</span>:<span class="string">"13:0-18:0"</span>&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>上面描述的就是这个文档中所有数据集中其中的一条数据。<br>可以发现json数据格式是按照键值对的形式进行存储的。</p>
<ul>
<li>business_id ： 商业店铺的id,用来唯一的标识这一个商铺</li>
<li>name : 商业店铺的名称</li>
<li>address : 商铺的位置</li>
<li>city : 城镇</li>
<li>state : 州县</li>
<li>postal_code : 邮政编码</li>
<li>latitude :纬度</li>
<li>longitude :经度</li>
<li>starts : 星级评分</li>
<li>review_count：评论数</li>
<li>is_open： 商家是否营业</li>
<li>attributes ：商家所进行的业务</li>
<li>categories: 类别</li>
<li>hours : 商家的营业时间</li>
</ul>
<h3 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h3><ol>
<li>统计出所有的商业类别，并且进行计算出商业类别的Top 10(categories)。</li>
<li>每个城市各种商业类型的商家数量,并且计算出商家数量最多的十个城市(city,categories)。</li>
<li>消费者评价最多的10种商业类别(review_count,categories)。</li>
<li>最受消费者欢迎的10种商业类别(starts)。</li>
<li>商业额外业务的评价情况。</li>
</ol>
<h3 id="主要的解决步骤"><a href="#主要的解决步骤" class="headerlink" title="主要的解决步骤"></a>主要的解决步骤</h3><ol>
<li>第一步 对数据进行预处理，剔除异常值</li>
<li>第二步 进行数据集的分析</li>
<li>第三步 对数据进行可视化分析</li>
</ol>
<h2 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h2><h3 id="所需要的包"><a href="#所需要的包" class="headerlink" title="所需要的包"></a>所需要的包</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf,SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> f</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<ul>
<li><p>pyspark<br>PySpark 是 Spark 为 Python 开发者提供的 API</p>
<ul>
<li>SparkContext<br>是程序的入口点，负责连接Spark集群。集群通过SparkContext进行资源管理器的通信以及进行资源的申请、任务的分配和监控，需要从SparkSession中获得</li>
<li>SparkConf<br>创建SparkContext前得使用SparkConf进行配置，以键值对形式进行</li>
</ul>
</li>
<li><p>pyspark.sql<br>一种解析传统SQL到大数据运算模型的引擎</p>
<ul>
<li>SparkSession<br>其为用户提供了一个统一的切入点来使用Spark的各项功能，并且允许用户通过它调用DataFrame和Dataset相关API来编写Spark程序</li>
<li>DataFrame（表）是Spark SQL对结构化数据的抽象。可以将DataFrame看做RDD</li>
<li>Dataset是数据的分布式集合</li>
</ul>
</li>
<li>pyspark.sql.function<br>可用于dataFram的内置功能列表</li>
<li>os<br>主要是针对操作系统的包，用来与操作系统进行交互，创建文件等。</li>
<li>json<br>Python里的json模块主要用于“Python数据与JSON格式的数据间相互转换”</li>
<li>pandas<br>pandas是一个强大的分析结构化数据的工具集；它的使用基础是Numpy（提供高性能的矩阵运算）；用于数据挖掘和数据分析，同时也提供数据清洗功能。</li>
<li>matplotlib.pyplot<br>是matlib的python版实现，用于绘图操作。</li>
</ul>
<h3 id="获取spark操作对象"><a href="#获取spark操作对象" class="headerlink" title="获取spark操作对象"></a>获取spark操作对象</h3><p>建立一个会话对象<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立配置文件</span></span><br><span class="line"><span class="comment">#builder用来创建一个Sparksession实例</span></span><br><span class="line"><span class="comment">#config 配置相关</span></span><br><span class="line"><span class="comment">#getOrCreate 有就获取没有就创建</span></span><br><span class="line">spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()</span><br></pre></td></tr></table></figure></p>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>下面对数据清洗 进行一个详细的分析。主要将数据中存在值缺失的数据，商家位置错误的数据（这里可以称为离群值）进行筛选。代码的详解解读，如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据清洗</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_process</span><span class="params">(raw_data_path)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 通过数据路径，读取数据，这里是json数据</span></span><br><span class="line">    business = spark.read.json(raw_data_path)</span><br><span class="line">    <span class="comment">#split(str, pattern, limit=-1)</span></span><br><span class="line">    <span class="comment">#str – 我们要分割的字符串</span></span><br><span class="line">    <span class="comment">#pattern 分割所用的正则表达式</span></span><br><span class="line">    split_col = f.split(business[<span class="string">'categories'</span>], <span class="string">','</span>)</span><br><span class="line">    <span class="comment">#withColumn(colName, col)</span></span><br><span class="line">    <span class="comment">#withColumn 负责在原有表的基础上新添加一列 colName是添加一列后的新的列名，col是新列的值 ？列名一样会怎么样处理（这里应该是会直接替代原来的，有待验证）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#filter 使用给定的条件 过滤行 这里是在所有的categories中过滤掉城市</span></span><br><span class="line">    <span class="comment"># dropna 至少又一个空缺值的行都会被删除</span></span><br><span class="line">    business = business.withColumn(<span class="string">"categories"</span>, split_col).filter(business[<span class="string">"city"</span>] != <span class="string">""</span>).dropna()</span><br><span class="line">    <span class="comment">#创建一个数据的临时视图，这个视图的周期与sparkSession相关联</span></span><br><span class="line">    business.createOrReplaceTempView(<span class="string">"business"</span>)</span><br><span class="line">    <span class="comment">#解析传统的sql到大数据运算模型 筛选出所需要的内容</span></span><br><span class="line">    <span class="comment">#cache 按照默认的存储级别 持久化dataFrame</span></span><br><span class="line">    b_etl = spark.sql(<span class="string">"SELECT business_id, name, city, state, latitude, longitude, stars, review_count, is_open, categories, attributes FROM business"</span>).cache()</span><br><span class="line">    <span class="comment">#将筛选完的数据 在进行一个临时视图 方便下一步的sql分析</span></span><br><span class="line">    b_etl.createOrReplaceTempView(<span class="string">"b_etl"</span>)</span><br><span class="line">    <span class="comment">#这里是筛选掉 离群值 （距离洲内商家平均位置的欧式距离）</span></span><br><span class="line">    <span class="comment">#b1 作为business的原始数据表 b2是在原始数据表的基础上计算每个州县的平均 经纬度 然后计算每一个商家在这个州县的欧式距离 并根据计算结果降序排列</span></span><br><span class="line">    outlier = spark.sql(</span><br><span class="line">        <span class="string">"SELECT b1.business_id, SQRT(POWER(b1.latitude - b2.avg_lat, 2) + POWER(b1.longitude - b2.avg_long, 2)) \</span></span><br><span class="line"><span class="string">        as dist FROM b_etl b1 INNER JOIN (SELECT state, AVG(latitude) as avg_lat, AVG(longitude) as avg_long \</span></span><br><span class="line"><span class="string">        FROM b_etl GROUP BY state) b2 ON b1.state = b2.state ORDER BY dist DESC"</span>)</span><br><span class="line">    <span class="comment">#创建一个新的临时视图 outlier</span></span><br><span class="line">    outlier.createOrReplaceTempView(<span class="string">"outlier"</span>)</span><br><span class="line">    <span class="comment">#从b_et1中 筛选出所有的距离小于10 的值。这对应到经纬度上面 已经是比较大的值了</span></span><br><span class="line">    joined = spark.sql(<span class="string">"SELECT b.* FROM b_etl b INNER JOIN outlier o ON b.business_id = o.business_id WHERE o.dist&lt;10"</span>)</span><br><span class="line">    <span class="comment">#将筛选后的数据进行存储 存储为parquet的格式</span></span><br><span class="line">    joined.write.parquet(<span class="string">"file:///home/hadoop/yelp-etl/business_etl"</span>, mode=<span class="string">"overwrite"</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="内容补充"><a href="#内容补充" class="headerlink" title="内容补充"></a>内容补充</h4><ol>
<li>parquet 文件格式<br>parquet采用不同的压缩比，能达到有效的压缩比。减少磁盘的使用。<br>parquet结合spark，可以完美的实现支持分区过滤。如，需要某个产品某段时间的数据，则hdfs只取这个文件夹。<br>列修剪：其实说简单点就是我们要取回的那些列的数据</li>
<li>离群值<br>离群值(outlier)，也称逸出值，是指在数据中有一个或几个数值与其他数值相比差异较大.</li>
<li>withColumn(colName, col)<br>  这里要解决的问题是，我们在项目中遗留的一个问题，withColumn往数据里面执行添加操作的时候，当colName的名字与原表中的名字一样的时候，添加操作是如何进行的。</li>
</ol>
<h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><p>这一部分主要对清理后的数据进行分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analysis</span><span class="params">(data_path)</span>:</span></span><br><span class="line">    <span class="comment"># 读取清理后的数据路径，存储的parque数据，并持久化到磁盘中</span></span><br><span class="line">    business = spark.read.parquet(data_path).cache()</span><br><span class="line">    <span class="comment">#将新的数据建立一个新的视图 business</span></span><br><span class="line">    business.createOrReplaceTempView(<span class="string">"business"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#从上面处理过的数据中，选择各种商业类别的洲县、城镇、星级评分、评论数</span></span><br><span class="line">    <span class="comment">#explode 在sql语句中用来处理array类型的数据。</span></span><br><span class="line">    part_business = spark.sql(<span class="string">"SELECT state, city, stars,review_count, explode(categories) AS category FROM business"</span>).cache()</span><br><span class="line">    <span class="comment">#默认显示前 20 行 并提示only showing top 20 rows</span></span><br><span class="line">    part_business.show()</span><br></pre></td></tr></table></figure>
<p>Start analysis data!<br>+—–+—————-+—–+————+——————–+<br>|state|            city|stars|review_count|            category|<br>+—–+—————-+—–+————+——————–+<br>|   AZ|         Phoenix|  4.0|          41|            Notaries|<br>|   AZ|         Phoenix|  4.0|          41|     Mailbox Centers|<br>|   AZ|         Phoenix|  4.0|          41|   Printing Services|<br>|   AZ|         Phoenix|  4.0|          41|      Local Services|<br>|   AZ|         Phoenix|  4.0|          41|    Shipping Centers|<br>|   NV|       Las Vegas|  4.0|         681|         Restaurants|<br>|   NV|       Las Vegas|  4.0|         681|                Bars|<br>|   NV|       Las Vegas|  4.0|         681|           Nightlife|<br>|   NV|       Las Vegas|  4.0|         681|      American (New)|<br>|   NV|       Las Vegas|  4.0|         681|             Seafood|<br>|   QC|Vaudreuil-Dorion|  4.0|           7|                Food|<br>|   QC|Vaudreuil-Dorion|  4.0|           7|            Bakeries|<br>|   AZ|      Scottsdale|  3.5|           5|            Shopping|<br>|   AZ|      Scottsdale|  3.5|           5|       Home &amp; Garden|<br>|   AZ|      Scottsdale|  3.5|           5|          Mattresses|<br>|   NC|       Charlotte|  3.0|          64|                Gyms|<br>|   NC|       Charlotte|  3.0|          64|        Sports Clubs|<br>|   NC|       Charlotte|  3.0|          64|         Active Life|<br>|   NC|       Charlotte|  3.0|          64| Fitness &amp; Instru…|<br>|   ON|     Mississauga|  4.5|          12|         Restaurants|<br>+—–+—————-+—–+————+——————–+<br>only showing top 20 rows</p>
<p>上述就是对处理完的数据进行一个显示以及筛选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将筛选的商业类别的相关信息 创建一个新的视图</span></span><br><span class="line">    part_business.createOrReplaceTempView(<span class="string">'part_business_1'</span>)</span><br><span class="line">    <span class="comment">#选择洲 城市 星级评定，评论数 </span></span><br><span class="line">    <span class="comment">#  REPLACE(category, ' ','')as new_category 的含义是对category 这一行进行‘’ 替换成‘’ 然后创建一个新的代表商家类别的列（相当于对这一列的数据进行了一个备份）</span></span><br><span class="line">    part_business = spark.sql(<span class="string">"SELECT state, city, stars, review_count, REPLACE(category, ' ','')as new_category FROM part_business_1"</span>)</span><br><span class="line">    <span class="comment"># 创建一个新的视图</span></span><br><span class="line">    part_business.createOrReplaceTempView(<span class="string">'part_business'</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 所有的不同的商家类别</span></span><br><span class="line">    print(<span class="string">"## All distinct categories"</span>)</span><br><span class="line">    <span class="comment"># 筛选所有种类的商家 分别是商家的id 以及 商家的种类</span></span><br><span class="line">    all_categories = spark.sql(<span class="string">"SELECT business_id, explode(categories) AS category FROM business"</span>)</span><br><span class="line">    <span class="comment">#将筛选出的数据重新创建一个新的视图</span></span><br><span class="line">    all_categories.createOrReplaceTempView(<span class="string">'all_categories'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 祛除重复的数据 并计算出所有种类的个数</span></span><br><span class="line">    distinct = spark.sql(<span class="string">"SELECT COUNT(DISTINCT(new_category)) FROM part_business"</span>)</span><br><span class="line">    distinct.show()</span><br></pre></td></tr></table></figure>
<p>上述过程是统计出所有种类的商家。</p>
<p> All distinct categories<br>+—————————-+<br>|count(DISTINCT new_category)|<br>+—————————-+<br>|                        1318|<br>+—————————-+</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"## Top 10 business categories"</span>)</span><br><span class="line">    <span class="comment">#统计出没种种类的商家的个数 并且按照降序排列</span></span><br><span class="line">    top_cat = spark.sql(<span class="string">"SELECT new_category, COUNT(*) as freq FROM part_business GROUP BY new_category ORDER BY freq DESC"</span>)</span><br><span class="line">    <span class="comment">#显示出排名前10的商家的种类</span></span><br><span class="line">    top_cat.show(<span class="number">10</span>) </span><br><span class="line">    <span class="comment">#将统计出的数据 存储为 json文件</span></span><br><span class="line">    top_cat.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/top_category"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201023212023388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在每个城市中商业种类的个数 仅按照商业种类的个数显示 前20条 </span></span><br><span class="line">   print(<span class="string">"## Top business categories - in every city"</span>)</span><br><span class="line">   top_cat_city = spark.sql(<span class="string">"SELECT city, new_category, COUNT(*) as freq FROM part_business GROUP BY city, new_category ORDER BY freq DESC"</span>)</span><br><span class="line">   top_cat_city.show()  </span><br><span class="line">   <span class="comment">#将数据存储到json中</span></span><br><span class="line">   top_cat.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/top_category_city"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 商业数量最多的城市</span></span><br><span class="line">    print(<span class="string">"## Cities with most businesses"</span>)</span><br><span class="line">    bus_city = spark.sql(<span class="string">"SELECT city, COUNT(business_id) as no_of_bus FROM business GROUP BY city ORDER BY no_of_bus DESC"</span>)</span><br><span class="line">    bus_city.show(<span class="number">10</span>)   </span><br><span class="line">    bus_city.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/top_business_city"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201023212642926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#每种商业种类的 平均评论数 </span></span><br><span class="line">    print(<span class="string">"## Average review count by category"</span>)</span><br><span class="line">    avg_city = spark.sql(</span><br><span class="line">        <span class="string">"SELECT new_category, AVG(review_count)as avg_review_count FROM part_business GROUP BY new_category ORDER BY avg_review_count DESC"</span>)</span><br><span class="line">    avg_city.show()  </span><br><span class="line">    avg_city.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/average_review_category"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201023212832651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这里其实也是显示了20行，就不截图太多了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#每种商业类别的 平均星级水平</span></span><br><span class="line">    print(<span class="string">"## Average stars by category"</span>)</span><br><span class="line">    avg_state = spark.sql(</span><br><span class="line">        <span class="string">"SELECT new_category, AVG(stars) as avg_stars FROM part_business GROUP BY new_category ORDER BY avg_stars DESC"</span>)</span><br><span class="line">    avg_state.show()   </span><br><span class="line">    avg_state.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/average_stars_category"</span>, mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure>
<p>由于字段 attribute 中的RestaurantsTakeout可能NULL的情况，所以需要利用dropna()处理缺失值的问题。该项对商家是否有’Take out’服务进行分析，统计出两种不同情况的商家的平均星级评分.对应的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 商家所进行的业务分析</span></span><br><span class="line">    print(<span class="string">"## Data based on Attribute"</span>)</span><br><span class="line">    <span class="comment">#仅筛选出 商家所进行的业务，星级，以及划分到的商业类别</span></span><br><span class="line">    for_att = spark.sql(<span class="string">"SELECT attributes, stars, explode(categories) AS category FROM business"</span>)</span><br><span class="line">    <span class="comment">#将筛选出的数据 创建一个新的视图</span></span><br><span class="line">    for_att.createOrReplaceTempView(<span class="string">"for_att"</span>)</span><br><span class="line">    <span class="comment">#对 商家是否 有外卖这个 业务进行分析</span></span><br><span class="line">    attribute = <span class="string">'RestaurantsTakeout'</span></span><br><span class="line">    attribute_score(attribute)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attribute_score</span><span class="params">(attribute)</span>:</span></span><br><span class="line">    <span class="comment"># 这里的format 表示用attribute的值代替attr的值</span></span><br><span class="line">    att = spark.sql(<span class="string">"SELECT attributes.&#123;attr&#125; as &#123;attr&#125;, category, stars FROM for_att"</span>.format(attr=attribute)).dropna()</span><br><span class="line">    att.createOrReplaceTempView(<span class="string">"att"</span>)</span><br><span class="line">    att_group = spark.sql(<span class="string">"SELECT &#123;attr&#125;, AVG(stars) AS stars FROM att GROUP BY &#123;attr&#125; ORDER BY stars"</span>.format(attr=attribute))</span><br><span class="line">    att_group.show()    </span><br><span class="line">    att_group.write.json(<span class="string">"file:///usr/local/spark/yelp/analysis/&#123;attr&#125;"</span>.format(attr=attribute), mode=<span class="string">'overwrite'</span>)</span><br></pre></td></tr></table></figure></p>
<p>到这里所有的数据分析的代码就讲解完了。接下来我们来看一下，对于我们统计出来的这些数据，我们那如何更直观的查看。也就是数据的可视化</p>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><p>这里我们进行的数据可视化是通过 python中的matlib包进行绘图表示的。</p>
<h4 id="数据的读取"><a href="#数据的读取" class="headerlink" title="数据的读取"></a>数据的读取</h4><p>我们先将上面已经分析过的数据并存储在磁盘上的数据路径自定义。（这一块系统可是无法自己找到）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">AVE_REVIEW_CATEGORY = <span class="string">'/usr/local/spark/yelp/analysis/average_review_category'</span></span><br><span class="line">TOP_CATEGORY_CITY = <span class="string">'/usr/local/spark/yelp/analysis/top_category_city'</span></span><br><span class="line">TOP_BUSINESS_CITY = <span class="string">'/usr/local/spark/yelp/analysis/top_business_city'</span></span><br><span class="line">TOP_CATEGORY = <span class="string">'/usr/local/spark/yelp/analysis/top_category'</span></span><br><span class="line">AVE_STARS_CATEGORY = <span class="string">'/usr/local/spark/yelp/analysis/average_stars_category'</span></span><br><span class="line">TAKEOUT = <span class="string">'/usr/local/spark/yelp/analysis/RestaurantsTakeout'</span></span><br></pre></td></tr></table></figure>
<h4 id="定义数据读取的函数"><a href="#定义数据读取的函数" class="headerlink" title="定义数据读取的函数"></a>定义数据读取的函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_json</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    <span class="comment">#读取这个路径下的所有文件的名称</span></span><br><span class="line">    json_path_names = os.listdir(file_path)</span><br><span class="line">    data = []</span><br><span class="line">    <span class="comment">#遍历所有的文件</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(len(json_path_names)):</span><br><span class="line">        <span class="comment">#拼接路径名称</span></span><br><span class="line">        json_path = file_path + <span class="string">'/'</span> + json_path_names[idx]</span><br><span class="line">        <span class="comment">#判断文件是不是json文件 如果是的话 就打开读取</span></span><br><span class="line">        <span class="keyword">if</span> json_path.endswith(<span class="string">'.json'</span>):</span><br><span class="line">            <span class="keyword">with</span> open(json_path) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="comment">#将读取的数据拼接到data中 返回读取到的数据</span></span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                    data.append(json.loads(line))</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<p>获得读取的所有的数据 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ave_review_category_list = read_json(AVE_REVIEW_CATEGORY)</span><br><span class="line">open_close_list = read_json(OPEN_CLOSE)</span><br><span class="line">top_category_city_list = read_json(TOP_CATEGORY_CITY)</span><br><span class="line">top_business_city_list = read_json(TOP_BUSINESS_CITY)</span><br><span class="line">top_category_list = read_json(TOP_CATEGORY)</span><br><span class="line">ave_stars_category_list = read_json(AVE_STARS_CATEGORY)</span><br><span class="line">takeout_list = read_json(TAKEOUT)</span><br></pre></td></tr></table></figure>
<h4 id="下面是数据的图形化展示"><a href="#下面是数据的图形化展示" class="headerlink" title="下面是数据的图形化展示"></a>下面是数据的图形化展示</h4><p>对于这一部分，对一部分进行讲解，因为其余的图形的绘画 的思路是一样的。不一样的地方，在于画图的语法不一样。（这里可以自行学习）<br><a href="https://matplotlib.org/gallery/index.html" target="_blank" rel="noopener">学习链接（marplotlib画图）</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在每个城市中商业种类的个数 仅按照商业种类的个数显示 前10条 根据商业种类出现的次数进行 排名 从小到大</span></span><br><span class="line">    top_category_list.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">'freq'</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#商业种类的名称</span></span><br><span class="line">    top_category_key = []</span><br><span class="line">    <span class="comment">#商业种类的统计个数</span></span><br><span class="line">    top_category_value = []</span><br><span class="line">    <span class="comment">#数据填充</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        one = top_category_list[idx]</span><br><span class="line">        top_category_key.append(one[<span class="string">'new_category'</span>])</span><br><span class="line">        top_category_value.append(one[<span class="string">'freq'</span>])</span><br><span class="line">    <span class="comment">#绘制条形图 截取前10名</span></span><br><span class="line">    plt.barh(top_category_key[:<span class="number">10</span>], top_category_value[:<span class="number">10</span>], tick_label=top_category_key[:<span class="number">10</span>])</span><br><span class="line">    <span class="comment">#标题</span></span><br><span class="line">    plt.title(<span class="string">'Top 10 Categories'</span>, size = <span class="number">16</span>)</span><br><span class="line">    <span class="comment">#x 的label为Frequency 条形图的宽度为 8 颜色 black</span></span><br><span class="line">    plt.xlabel(<span class="string">'Frequency'</span>,size =<span class="number">8</span>, color = <span class="string">'Black'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Category'</span>,size = <span class="number">8</span>, color = <span class="string">'Black'</span>)</span><br><span class="line">    <span class="comment"># 会自动填充子图参数 让子图能够填充整个图像区域。（仅仅检查 坐标轴的标签，刻度标签以及标题的部分）</span></span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20201024111407659.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20201024112306697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这样是不是看起来就更加直观了呢！</p>
<p>显示的图片不是很清晰，或者标题的字体格式等也是可以调的，这里就不在详细的介绍了。</p>
<p>源码就存在我的jupyter上了（不过需要我开启服务器才可以访问）<a href="http://www.itgorge.ltd:8888/notebooks/PYSparkTest.ipynb" target="_blank" rel="noopener">源码</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/10/24/emmm-spark商业数据分析案例讲解/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="emmm-spark商业数据分析案例讲解">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-大数据分析之阿里云安装Spark" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/16/大数据分析之阿里云安装Spark/" class="article-date">
  	<time datetime="2020-10-16T14:31:12.930Z" itemprop="datePublished">2020-10-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/16/大数据分析之阿里云安装Spark/">
        大数据分析之阿里云安装Spark
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在我们已经安装好Hadoop的阿里云上，进行如下操作</p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="https://www.apache.org/dyn/closer.lua/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz" target="_blank" rel="noopener">下载链接</a><br>使用wget在linux上进行下载即可</p>
<h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf spark-3.0.1-bin-hadoop2.7.tgz -C /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure>
<h2 id="改名-修改文件权限"><a href="#改名-修改文件权限" class="headerlink" title="改名+修改文件权限"></a>改名+修改文件权限</h2><p>因为我在搭建hadoop的时候，在root用户上新创建了一个新的用户，因此，要把权限给hadoop用户</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mv ./spark-3.0.1-bin-hadoop2.7 ./spark</span><br><span class="line">sudo chown -R hadoop ./spark</span><br></pre></td></tr></table></figure>
<h2 id="更改为可执行文件"><a href="#更改为可执行文件" class="headerlink" title="更改为可执行文件"></a>更改为可执行文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp ./conf/spark-env.sh.template ./conf/spark-env.sh</span><br></pre></td></tr></table></figure>
<p>编辑spark-env.sh文件(vim ./conf/spark-env.sh)，在第一行添加以下配置信息:</p>
<p>export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</p>
<p>有了上面的配置信息以后，Spark就可以把数据存储到Hadoop分布式文件系统HDFS中，也可以从HDFS中读取数据。如果没有配置上面信息，Spark就只能读写本地数据，无法读写HDFS数据。<br>配置完成后就可以直接使用，不需要像Hadoop运行启动命令。<br>通过运行Spark自带的示例，验证Spark是否安装成功。</p>
<h2 id="启动进入spark-shell交互式执行环境"><a href="#启动进入spark-shell交互式执行环境" class="headerlink" title="启动进入spark-shell交互式执行环境"></a>启动进入spark-shell交互式执行环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark</span><br><span class="line">./bin/spark-shell</span><br></pre></td></tr></table></figure>
<p>我们就可以看到Spark的信息，这样spark就安装成功了<br>如果想要退出spark的话，执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; :quit</span><br></pre></td></tr></table></figure>
<h2 id="测试Spark是否可以正常访问Ubuntu系统中的本地文件"><a href="#测试Spark是否可以正常访问Ubuntu系统中的本地文件" class="headerlink" title="测试Spark是否可以正常访问Ubuntu系统中的本地文件"></a>测试Spark是否可以正常访问Ubuntu系统中的本地文件</h2><p>在本地创建一个文本文件，里面输入hello word</p>
<p>开启spark ,写入测试文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cala&gt; val line=sc.textFile(<span class="string">"file:///home/hadoop/a.txt"</span>)</span><br><span class="line">line: org.apache.spark.rdd.RDD[String] = file:///home/hadoop/a.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="built_in">print</span>(line.count())</span><br><span class="line">1</span><br></pre></td></tr></table></figure>
<h2 id="测试Spark是否能够正常访问Hadoop中的HDFS"><a href="#测试Spark是否能够正常访问Hadoop中的HDFS" class="headerlink" title="测试Spark是否能够正常访问Hadoop中的HDFS"></a>测试Spark是否能够正常访问Hadoop中的HDFS</h2><p>首先执行一下jps检查一下，hadoop是否已经正常启动。<br>接下来，我们将在HDFS中已经准备好的测试文件，来查看一下主要的文件信息<br>，这里假设大家都已经掌握了Hadoop的基本知识。 这是在我的主文件下。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -cat /user/hadoop/text.txt</span><br></pre></td></tr></table></figure></p>
<p>我们再来执行一下<br>val line=sc.textFile(“/user/hadoop/text.txt”)<br> println(line.count())<br> 来检查一下。<br> <em>注意：在spark-shell交互式环境中，要访问HDFS中的文件时，可以直接使 sc.textFile(“/user/linziyu/word.txt”)和sc.textFile(“word.txt”)这两种路径格式</em><br> 这样我们的Spark就搭建完了。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/10/16/大数据分析之阿里云安装Spark/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="大数据分析之阿里云安装Spark">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-大数据-HBase实验以及讲解" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/15/大数据-HBase实验以及讲解/" class="article-date">
  	<time datetime="2020-10-15T12:13:54.270Z" itemprop="datePublished">2020-10-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/15/大数据-HBase实验以及讲解/">
        大数据-Hbase实验以及讲解
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>HBase是一个面向列的高可靠、高性能、可伸缩的分布式数据库。是Google公司的BigTable的开源实现，主要用来存储<a href="https://baike.baidu.com/item/%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE/309808?fr=aladdin" target="_blank" rel="noopener">非结构化数据</a>和<a href="https://baike.baidu.com/item/%E5%8D%8A%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE/3193001?fr=aladdin" target="_blank" rel="noopener">半结构化数据</a>的松散数据，支持大规模海量数据的、分布式并发数据处理效率极高；适用于廉价设备，适合读操作，不适合写操作。HBase可以直接使用本地文件系统而不用HDFS作为底层数据存储方式。为了提高数据可靠性和系统的健壮性，一般都使用HDFS作为底层数据存储方式。</p>
<h2 id="HBase与传统数据库的对比"><a href="#HBase与传统数据库的对比" class="headerlink" title="HBase与传统数据库的对比"></a>HBase与传统数据库的对比</h2><table>
<thead>
<tr>
<th>对比项目</th>
<th>传统数据库</th>
<th>HBase</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据类型</td>
<td>关系型模型</td>
<td>未经解释的字符串</td>
</tr>
<tr>
<td>数据操作</td>
<td>插入、删除、更新、查询等已经多表连接等</td>
<td>只有简单的插入、查询、删除、清空等。避免了复杂的表格之间的关系，只采用单表的主键查询，无法实现表的连接操作</td>
</tr>
<tr>
<td>存储模式</td>
<td>基于行存储，元组或者行会连续的存储在磁盘页</td>
<td>基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的</td>
</tr>
<tr>
<td>数据索引</td>
<td>通常可以针对不同的列构建复杂的多个索引</td>
<td>只有一个索引-行键</td>
</tr>
<tr>
<td>数据维护</td>
<td>更新操作的时候，新的值会覆盖旧的值</td>
<td>不会删除旧版的数据，而是生成一个新的版本</td>
</tr>
<tr>
<td>可伸缩性</td>
<td>很难实现横向扩展，纵向扩展有限</td>
<td>很好的实现水平扩展</td>
</tr>
</tbody>
</table>
<h2 id="数据模型的新的概念"><a href="#数据模型的新的概念" class="headerlink" title="数据模型的新的概念"></a>数据模型的新的概念</h2><ul>
<li><p>列族<br>一个表被分成许多个列族的组合。列族需要在表创建的时候就创建好，数量不能太多（HBa se的一些缺陷导致的）,存储在同一个列族当中的数据，通常都是属于同一种数据类型的。在存储的时候，列明都以列族作为前缀的。比如，course:history和 course:math这两个列都属于courses这个列族</p>
</li>
<li><p>列限定符</p>
</li>
</ul>
<p>列族里面的数据通过列限定符来定位。列限定符不用事先定义，也不需要在不同行之间保持一致。</p>
<ul>
<li><p>时间戳<br>每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引。每次对一个单元格执行操作的时候，HBa se都会隐式的自动生成并存储一个时间戳。</p>
</li>
<li><p>数据坐标</p>
<p>传统的数据库我们都是通过二维坐标进行取值的，但是对于HBase来讲，需要根据[行键、列族、列限定符、时间戳]来确定一个单元格。</p>
<h2 id="物理视图"><a href="#物理视图" class="headerlink" title="物理视图"></a>物理视图</h2></li>
</ul>
<p>对于数据表的观察，便于我们观察的是概念视图，但是在HBa se中实际存储的是按照数据的物理视图进行存储的。物理视图是采用了基于列的存储方式，而不是像传统的方式那样基于行的存储方式。<br><img src="https://img-blog.csdnimg.cn/20201014150445658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于在概念视图中，空的列不会存储成null,而是根本就不会存储。</p>
<p>列式数据库主要适合于批量数据处理和即席查询 。<br>他的优点是：<em>可以降低I/O开销，支持大并发用户查询，处理速度比传统方法快100倍。</em><br>他的缺点是：执行连接操作时需要昂贵的元组重构代价，因为一个元组的不同属性被分散到不同的磁盘页中存储，当需要一个完整的元组的时候，就要从多个磁盘页中读取相应字段的值来重新组合得到原来的一个元组。</p>
<h2 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h2><p>主要理解HBa se架构个部分的作用，主要包括：</p>
<ul>
<li>客户端</li>
<li>Zookper服务器</li>
<li>Master</li>
<li><p>Region服务器</p>
<ul>
<li>Store</li>
<li>HLog文件<h2 id="HBase-常用的She-l-l命令"><a href="#HBase-常用的She-l-l命令" class="headerlink" title="HBase 常用的She l l命令"></a>HBase 常用的She l l命令</h2>自行学习，网上资料很多<h2 id="HBase-常用的Java-API-及应用实例"><a href="#HBase-常用的Java-API-及应用实例" class="headerlink" title="HBase 常用的Java API 及应用实例"></a>HBase 常用的Java API 及应用实例</h2>自行学习，网上资料很多<br>主要包括：HBaseConfiguration、HTableDescriptor、HcolumnDescriptor、Put、Get、ResultScanner、Resul、Scan。<h2 id="HBase的安装"><a href="#HBase的安装" class="headerlink" title="HBase的安装"></a>HBase的安装</h2></li>
</ul>
</li>
<li><p>可以使用wget命令在<a href="http://archive.apache.org/dist/hbase/" target="_blank" rel="noopener">HBase的官网</a>下载想要使用的版本</p>
</li>
<li>解压</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">sudo tar -zxf ~/下载/hbase-2.2.2-bin.tar.gz -C /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure>
<ul>
<li>更改名称</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sudo mv ./hbase-2.2.2 ./hbase</span><br></pre></td></tr></table></figure>
<ul>
<li>更改权限</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sudo chown -R hadoop ./hbase</span><br></pre></td></tr></table></figure>
<ul>
<li>配置环境变量</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">//如果没有引入过PATH 直接添加下面的代码，如果引入过，就将路径添加到path路径的后面即可</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/<span class="built_in">local</span>/hbase/bin</span><br></pre></td></tr></table></figure>
<p>执行命令，让配置生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<ul>
<li>添加HBase的权限</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">sudo chown -R hadoop ./hbase       <span class="comment">#将hbase下的所有文件的所有者改为hadoop，hadoop是当前用户的用户名。</span></span><br></pre></td></tr></table></figure>
<ul>
<li>查看版本，确保安装成功</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/hbase/bin/hbase version</span><br></pre></td></tr></table></figure>
<h2 id="伪分布式配置"><a href="#伪分布式配置" class="headerlink" title="伪分布式配置"></a>伪分布式配置</h2><ul>
<li>配置/usr/local/hbase/conf/hbase-env.sh。命令如下</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/local/hbase/conf/hbase-env.sh</span><br></pre></td></tr></table></figure>
<p>配置JAVA_HOME，HBASE_CLASSPATH，HBASE_MANAGES_ZK.<br>HBASE_CLASSPATH设置为本机HBase安装目录下的conf目录（即/usr/local/hbase/conf）</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/jdk1.<span class="number">8.0</span>_162</span><br><span class="line">export HBASE_CLASSPATH=/usr/local/hbase/conf </span><br><span class="line">export HBASE_MANAGES_ZK=true</span><br></pre></td></tr></table></figure>
<ul>
<li>配置/usr/local/hbase/conf/hbase-site.xml<br>用命令vi打开并编辑hbase-site.xml，命令如下</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/local/hbase/conf/hbase-site.xml</span><br></pre></td></tr></table></figure>
<p>修改hbase.rootdir，指定HBase数据在HDFS上的存储路径；将属性hbase.cluter.distributed设置为true。假设当前Hadoop集群运行在伪分布式模式下，在本机上运行，且NameNode运行在9000端口</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://localhost:<span class="number">9000</span>/hbase&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>接下来测试运行HBase<br>启动hbase的时候一定要确保hadoop已经成功启动</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hbase</span><br><span class="line">bin/start-hbase.sh</span><br></pre></td></tr></table></figure>
<p>成功安装配置好之后，下面就开始我们基本的实验吧</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="现有以下关系型数据库中的表和数据，要求将其转换为适合于HBase存储的表并插入数据："><a href="#现有以下关系型数据库中的表和数据，要求将其转换为适合于HBase存储的表并插入数据：" class="headerlink" title="现有以下关系型数据库中的表和数据，要求将其转换为适合于HBase存储的表并插入数据："></a>现有以下关系型数据库中的表和数据，要求将其转换为适合于HBase存储的表并插入数据：</h3><p>学生表（Student）<br>学号（S_No）     | 姓名（S_Name) |性别（S_Sex)|年龄（S_Age）<br>——– | —–|—-|—-<br>2015001  | Zhangsan|male|23<br>2015002  | Mary|female|22<br>2015003  | Lisi |male|24<br>下面先插入s003 学生的信息<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> hbase(main):<span class="number">008</span>:<span class="number">0</span>&gt;create <span class="string">'Student'</span>,<span class="string">'S_No'</span>,<span class="string">'S_Name'</span>,<span class="string">'S_Sex'</span>,<span class="string">'S_Age'</span></span><br><span class="line">hbase(main):<span class="number">029</span>:<span class="number">0</span>&gt; put <span class="string">'Student'</span>,<span class="string">'s003'</span>,<span class="string">'S_No'</span>,<span class="string">'2015003'</span></span><br><span class="line">Took <span class="number">0.0138</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">030</span>:<span class="number">0</span>&gt; put <span class="string">'Student'</span>,<span class="string">'s003'</span>,<span class="string">'S_Name'</span>,<span class="string">'Lisi'</span></span><br><span class="line">Took <span class="number">0.0118</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">031</span>:<span class="number">0</span>&gt; put <span class="string">'Student'</span>,<span class="string">'s003'</span>,<span class="string">'S_Sex'</span>,<span class="string">'male'</span></span><br><span class="line">Took <span class="number">0.0090</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">032</span>:<span class="number">0</span>&gt; put <span class="string">'Student'</span>,<span class="string">'s003'</span>,<span class="string">'S_Age'</span>,<span class="string">'24'</span></span><br></pre></td></tr></table></figure></p>
<p>课程表（Course）<br>课程号（C_No）    | 课程名（C_Name） |学分（C_Credit）<br>——– | —–|—-|—-<br>123001  | Math|2.0<br>123002 | Computer Science|5.0<br>123003  |English|3.0</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">041</span>:<span class="number">0</span>&gt; create <span class="string">'Course'</span>,<span class="string">'C_No'</span>,<span class="string">'C_Name'</span>,<span class="string">'C_Credit'</span></span><br><span class="line">Created table Course</span><br><span class="line">Took <span class="number">1.3558</span> seconds                                                                                                                                                                                         </span><br><span class="line">=&gt; Hbase::Table - Course</span><br><span class="line">hbase(main):<span class="number">042</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'C001'</span>,<span class="string">'C_No'</span>,<span class="string">'2015001'</span></span><br><span class="line">Took <span class="number">0.0373</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">043</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'C001'</span>,<span class="string">'C_Name'</span>,<span class="string">'Math'</span></span><br><span class="line">Took <span class="number">0.0097</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">044</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'C001'</span>,<span class="string">'C_No'</span>,<span class="string">'123001'</span></span><br><span class="line">Took <span class="number">0.0060</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">045</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'C001'</span>,<span class="string">'C_Credit'</span>,<span class="string">'2.0'</span></span><br><span class="line">Took <span class="number">0.0093</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">046</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'c002'</span>,<span class="string">'C_No'</span>,<span class="string">'123002'</span></span><br><span class="line">Took <span class="number">0.0049</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">047</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'c002'</span>,<span class="string">'C_Name'</span>,<span class="string">'Computer'</span></span><br><span class="line">Took <span class="number">0.1125</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">048</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'c002'</span>,<span class="string">'C_Credit'</span>,<span class="string">'5.0'</span></span><br><span class="line">Took <span class="number">0.0107</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">049</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'c003'</span>,<span class="string">'C_No'</span>,<span class="string">'123003'</span></span><br><span class="line">Took <span class="number">0.0097</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">050</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'c003'</span>,<span class="string">'C_Name'</span>,<span class="string">'English'</span></span><br><span class="line">Took <span class="number">0.0060</span> seconds                                                                                                                                                                                         </span><br><span class="line">hbase(main):<span class="number">051</span>:<span class="number">0</span>&gt; put <span class="string">'Course'</span>,<span class="string">'c003'</span>,<span class="string">'C_Credit'</span>,<span class="string">'3.0'</span></span><br><span class="line">Took <span class="number">0.0089</span> seconds</span><br></pre></td></tr></table></figure>
<p>选课表（SC）<br>学号（SC_Sno）    | 课程号（SC_Cno））|成绩（SC_Score）<br>——– | —–|—-|—-<br>2015001  | 123001|86<br>2015001 | 123003|69<br>2015002  |123002|77<br>2015002  | 123003|99<br>2015003 | 123001|98<br>2015003  |123002|95</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create <span class="string">'SC'</span>,<span class="string">'SC_Sno'</span>,<span class="string">'SC_Cno'</span>,<span class="string">'SC_Score'</span></span><br><span class="line">Created table SC</span><br><span class="line">Took <span class="number">1.2786</span> seconds                                                                                                                                                                                         </span><br><span class="line">=&gt; Hbase::Table - SC</span><br><span class="line">hbase(main):<span class="number">053</span>:<span class="number">0</span>&gt; put <span class="string">'SC'</span>,<span class="string">'sc001'</span>,<span class="string">'SC_Sno'</span>,<span class="string">'2015001'</span></span><br><span class="line">NoMethodError: undefined method `ut<span class="string">' for main:Object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">hbase(main):054:0&gt; put '</span>SC<span class="string">','</span>sc001<span class="string">','</span>SC_Sno<span class="string">','</span><span class="number">2015001</span><span class="string">'</span></span><br><span class="line"><span class="string">Took 0.0210 seconds                                                                                                                                                                                         </span></span><br><span class="line"><span class="string">hbase(main):055:0&gt; put '</span>SC<span class="string">','</span>sc001<span class="string">','</span>SC_Cno<span class="string">','</span><span class="number">123001</span><span class="string">'</span></span><br><span class="line"><span class="string">Took 0.0201 seconds                                                                                                                                                                                         </span></span><br><span class="line"><span class="string">hbase(main):056:0&gt; put '</span>SC<span class="string">','</span>sc001<span class="string">','</span>SC_Score<span class="string">','</span><span class="number">86</span><span class="string">'</span></span><br></pre></td></tr></table></figure>
<p>这样，我们的表还有数据就填充完了，上面因为一些数据的填充的过程都是一样的，因此就写了一个实例来演示一下，需要注意的是<em>表格中每一个行的数据，都需要为他增加一个主键，也就是语句中的sc001的部分，因为hba se是列存储的，这个用来表示每一行，因此，对应每一行的时候，这个值要有所区分</em></p>
<h3 id="编程实现以下指定功能，并用Hadoop提供的HBase-Shell命令完成相同任务："><a href="#编程实现以下指定功能，并用Hadoop提供的HBase-Shell命令完成相同任务：" class="headerlink" title="编程实现以下指定功能，并用Hadoop提供的HBase Shell命令完成相同任务："></a>编程实现以下指定功能，并用Hadoop提供的HBase Shell命令完成相同任务：</h3><ul>
<li>先是shell命令</li>
</ul>
<p>（1）列出HBase所有的表的相关信息，例如表名；</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">073</span>:<span class="number">0</span>&gt; list</span><br></pre></td></tr></table></figure>
<p>（2）在终端打印出指定的表的所有记录数据；</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scan <span class="string">'Student'</span></span><br></pre></td></tr></table></figure>
<p>（3）向已经创建好的表添加和删除指定的列族或列；</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create <span class="string">'s1'</span>,<span class="string">'score'</span></span><br><span class="line">put <span class="string">'s1'</span>,<span class="string">'zhangsan'</span>,<span class="string">'score:math'</span>,<span class="string">'69'</span></span><br><span class="line">delete <span class="string">'s1'</span>,<span class="string">'zhangsan'</span>,<span class="string">'score:math'</span></span><br></pre></td></tr></table></figure>
<p>（4）清空指定的表的所有记录数据；</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">078</span>:<span class="number">0</span>&gt; truncate <span class="string">'s1'</span></span><br></pre></td></tr></table></figure>
<p>（5）统计表的行数。</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase&gt; count <span class="string">'s1'</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Java命令</li>
</ul>
<p>使用HBase Java API进行编程控制<br>在进行编程之前，我们先进行一些前期的准备工作，准备好编程需要的环境。<br>当我们建立好普通的java项目之后，首先要进行一个导包的操作。<br>(导包操作以及建立项目的过程，不会的自行百度学习)<br>所需要的包位于</p>
<p><1> 进入到“/usr/local/hbase/lib”目录，选中该目录下的所有jar文件（注意，不要选中client-facing-thirdparty、ruby、shaded-clients和zkcli这四个目录）</1></p>
<p><2>在“client-facing-thirdparty”目录下（如下图所示），选中所有jar文件<br>上面就是我们所需要的全部的包了。</2></p>
<p>在这个项目下，建立一个类就可以进行编程了。<br>下面是上面五个小实验的详细代码 讲解，需要执行哪一个过程，在main函数中，调用即可。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test1;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleForHBase</span> </span>&#123;</span><br><span class="line">	<span class="comment">//首先定义一个 与数据库连接所需要的配置文件</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration configuration;</span><br><span class="line">    <span class="comment">//定义一个连接对象</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Connection connection;</span><br><span class="line">    <span class="comment">//定义一个操作数据库的对象。管理员可用于创建，删除，列出，启用和禁用以及以其他方式修改表以及执行其他管理操作。</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        createTable(<span class="string">"student"</span>,<span class="keyword">new</span> String[]&#123;<span class="string">"score"</span>&#125;);</span><br><span class="line">        insertData(<span class="string">"student"</span>,<span class="string">"zhangsan"</span>,<span class="string">"score"</span>,<span class="string">"English"</span>,<span class="string">"69"</span>);</span><br><span class="line">        insertData(<span class="string">"student"</span>,<span class="string">"zhangsan"</span>,<span class="string">"score"</span>,<span class="string">"Math"</span>,<span class="string">"86"</span>);</span><br><span class="line">        insertData(<span class="string">"student"</span>,<span class="string">"zhangsan"</span>,<span class="string">"score"</span>,<span class="string">"Computer"</span>,<span class="string">"77"</span>);</span><br><span class="line">        getData(<span class="string">"student"</span>, <span class="string">"zhangsan"</span>, <span class="string">"score"</span>,<span class="string">"English"</span>);</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="comment">//初始化 连接数据库所需要的 配置文件，连接对象，以及管理员</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">        configuration  = HBaseConfiguration.create();</span><br><span class="line">        configuration.set(<span class="string">"hbase.rootdir"</span>,<span class="string">"hdfs://0.0.0.0:8020/hbase"</span>);</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            admin = connection.getAdmin();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> <span class="comment">//设置数据库连接完成之后的关闭操作</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(admin != <span class="keyword">null</span>)&#123;</span><br><span class="line">            	<span class="comment">//管理员权限关闭</span></span><br><span class="line">                admin.close();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">null</span> != connection)&#123;</span><br><span class="line">            	<span class="comment">//连接关闭</span></span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 第一个题 列出HBase所有的表的相关信息</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">listTables</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        init();<span class="comment">//建立连接</span></span><br><span class="line">        List&lt;TableDescriptor&gt; tableDescriptors = admin.listTableDescriptors();</span><br><span class="line">        <span class="keyword">for</span>(TableDescriptor tableDescriptor : tableDescriptors)&#123;</span><br><span class="line">            TableName tableName = tableDescriptor.getTableName();</span><br><span class="line">            System.out.println(<span class="string">"Table:"</span> + tableName);</span><br><span class="line">        &#125;</span><br><span class="line">        close();<span class="comment">//关闭连接</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//第二题 在终端打印出指定的表的所有记录数据</span></span><br><span class="line">    </span><br><span class="line">  <span class="comment">//在终端打印出指定的表的所有记录数据</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getData</span><span class="params">(String tableName)</span><span class="keyword">throws</span>  IOException</span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        <span class="comment">//根据表名 获得一个表对象</span></span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="comment">// 获得一个查询表的查询对象</span></span><br><span class="line">        Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">        <span class="comment">//使用查询对象，获得查询到的结果（Result）集合  ResultScanner</span></span><br><span class="line">        ResultScanner scanner = table.getScanner(scan);<span class="comment">//获取行的遍历器</span></span><br><span class="line">        <span class="keyword">for</span> (Result result:scanner)&#123;</span><br><span class="line">        	<span class="comment">//将每一条Result的结果 打印输出</span></span><br><span class="line">            printRecoder(result);</span><br><span class="line">        &#125;</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//打印一条记录的详情</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printRecoder</span><span class="params">(Result result)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    	<span class="comment">//每一个列又包含多条信息 ，因此 需要迭代打印输出 </span></span><br><span class="line">        <span class="keyword">for</span>(Cell cell:result.rawCells())&#123;</span><br><span class="line">            System.out.print(<span class="string">"行健: "</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getRowArray(),cell.getRowOffset(), cell.getRowLength())));</span><br><span class="line">            System.out.print(<span class="string">"列簇: "</span>+<span class="keyword">new</span> String( Bytes.toString(cell.getFamilyArray(),cell.getFamilyOffset(), cell.getFamilyLength()) ));</span><br><span class="line">            System.out.print(<span class="string">" 列: "</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getQualifierArray(),cell.getQualifierOffset(), cell.getQualifierLength())));</span><br><span class="line">            System.out.print(<span class="string">" 值: "</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getValueArray(),cell.getValueOffset(), cell.getValueLength())));</span><br><span class="line">            System.out.println(<span class="string">"时间戳: "</span>+cell.getTimestamp());            </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"> </span><br><span class="line"> <span class="comment">//第三题 向表中 添加数据 所需要的关键字 与 shell的put语句 是对应的</span></span><br><span class="line">    <span class="comment">//colFamily代表的是列簇 如果列为空，那么应设置col的值为“”</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insertData</span><span class="params">(String tableName,String rowKey,String colFamily,String col,String val)</span> <span class="keyword">throws</span> IOException </span>&#123; </span><br><span class="line">      init();</span><br><span class="line">      <span class="comment">//建立连接 获取表</span></span><br><span class="line">    	Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">    	<span class="comment">//语句执行 添加</span></span><br><span class="line">        Put put = <span class="keyword">new</span> Put(rowKey.getBytes());</span><br><span class="line">        put.addColumn(colFamily.getBytes(),col.getBytes(), val.getBytes());</span><br><span class="line">        table.put(put);</span><br><span class="line">        table.close(); </span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">//删除数据</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleRow</span><span class="params">(String tableName,String rowKey,String colFamily,String col)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Delete delete = <span class="keyword">new</span> Delete(rowKey.getBytes());</span><br><span class="line">        <span class="comment">//删除指定列族</span></span><br><span class="line">        delete.addFamily(Bytes.toBytes(colFamily));</span><br><span class="line">        <span class="comment">//删除指定列</span></span><br><span class="line">        delete.addColumn(Bytes.toBytes(colFamily),Bytes.toBytes(col));</span><br><span class="line">        table.delete(delete);</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"> <span class="comment">//第四题 清空指定的表的所有记录数据；</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">clearRows</span><span class="params">(String tableName)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        TableName tablename = TableName.valueOf(tableName);</span><br><span class="line">        admin.disableTable(tablename);</span><br><span class="line">        admin.deleteTable(tablename);</span><br><span class="line">        TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tablename);</span><br><span class="line">        admin.createTable(tableDescriptor.build());        </span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//第五题 统计表的行数</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">countRows</span><span class="params">(String tableName)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">        ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">        <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (Result result = scanner.next();result!=<span class="keyword">null</span>;result=scanner.next())&#123;</span><br><span class="line">            num++;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"行数:"</span>+ num);</span><br><span class="line">        scanner.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//创建表</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String myTableName,String[] colFamily)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        TableName tableName = TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span>(admin.tableExists(tableName))&#123;</span><br><span class="line">            System.out.println(<span class="string">"talbe is exists!"</span>);</span><br><span class="line">            <span class="comment">//删除原来的表</span></span><br><span class="line">            admin.disableTable(tablename);</span><br><span class="line">            admin.deleteTable(tablename);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//创建新的表</span></span><br><span class="line">            TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span>(String str:colFamily)&#123;</span><br><span class="line">                ColumnFamilyDescriptor family = </span><br><span class="line">ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//获取表中的数据</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getData</span><span class="params">(String tableName,String rowKey,String colFamily, String col)</span><span class="keyword">throws</span>  IOException</span>&#123; </span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Get get = <span class="keyword">new</span> Get(rowKey.getBytes());</span><br><span class="line">        get.addColumn(colFamily.getBytes(),col.getBytes());</span><br><span class="line">        Result result = table.get(get);</span><br><span class="line">        System.out.println(<span class="keyword">new</span> String(result.getValue(colFamily.getBytes(),col==<span class="keyword">null</span>?<span class="keyword">null</span>:col.getBytes())));</span><br><span class="line">        table.close(); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>同时完成：<br>(1)createTable(String tableName, String[] fields)<br>创建表，参数tableName为表的名称，字符串数组fields为存储记录各个域名称的数组。要求当HBase已经存在名为tableName的表的时候，先删除原有的表，然后再创建新的表。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String myTableName,String[] colFamily)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        TableName tableName = TableName.valueOf(myTableName);</span><br><span class="line">        <span class="keyword">if</span>(admin.tableExists(tableName))&#123;</span><br><span class="line">            System.out.println(<span class="string">"talbe is exists!"</span>);</span><br><span class="line">            <span class="comment">//删除原来的表</span></span><br><span class="line">            admin.disableTable(tablename);</span><br><span class="line">            admin.deleteTable(tablename);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//创建新的表</span></span><br><span class="line">            TableDescriptorBuilder tableDescriptor = TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">            <span class="keyword">for</span>(String str:colFamily)&#123;</span><br><span class="line">                ColumnFamilyDescriptor family = </span><br><span class="line">ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(str)).build();</span><br><span class="line">                tableDescriptor.setColumnFamily(family);</span><br><span class="line">            &#125;</span><br><span class="line">            admin.createTable(tableDescriptor.build());</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>(2)addRecord(String tableName, String row, String[] fields, String[] values)<br>向表tableName、行row（用S_Name表示）和字符串数组files指定的单元格中添加对应的数据values。其中fields中每个元素如果对应的列族下还有相应的列限定符的话，用“columnFamily:column”表示。例如，同时向“Math”、“Computer Science”、“English”三列添加成绩时，字符串数组fields为{“Score:Math”,”Score；Computer Science”,”Score:English”}，数组values存储这三门课的成绩。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addRecord</span><span class="params">(String tableName,String row,String[] fields,String[] values)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i != fields.length;i++)&#123;</span><br><span class="line">            Put put = <span class="keyword">new</span> Put(row.getBytes());</span><br><span class="line">            String[] cols = fields[i].split(<span class="string">":"</span>);</span><br><span class="line">            put.addColumn(cols[<span class="number">0</span>].getBytes(), cols[<span class="number">1</span>].getBytes(), values[i].getBytes());</span><br><span class="line">            table.put(put);</span><br><span class="line">        &#125;</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>(3)scanColumn(String tableName, String column)<br>浏览表tableName某一列的数据，如果某一行记录中该列数据不存在，则返回null。要求当参数column为某一列族名称时，如果底下有若干个列限定符，则要列出每个列限定符代表的列的数据；当参数column为某一列具体名称（例如“Score:Math”）时，只需要列出该列的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">scanColumn</span><span class="params">(String tableName,String column)</span><span class="keyword">throws</span>  IOException</span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">        scan.addFamily(Bytes.toBytes(column));</span><br><span class="line">        ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">        <span class="keyword">for</span> (Result result = scanner.next(); result != <span class="keyword">null</span>; result = scanner.next())&#123;</span><br><span class="line">            showCell(result);</span><br><span class="line">        &#125;</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//格式化输出</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">showCell</span><span class="params">(Result result)</span></span>&#123;</span><br><span class="line">        Cell[] cells = result.rawCells();</span><br><span class="line">        <span class="keyword">for</span>(Cell cell:cells)&#123;</span><br><span class="line">            System.out.println(<span class="string">"RowName:"</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getRowArray(),cell.getRowOffset(), cell.getRowLength()))+<span class="string">" "</span>);</span><br><span class="line">            System.out.println(<span class="string">"Timetamp:"</span>+cell.getTimestamp()+<span class="string">" "</span>);</span><br><span class="line">            System.out.println(<span class="string">"column Family:"</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getFamilyArray(),cell.getFamilyOffset(), cell.getFamilyLength()))+<span class="string">" "</span>);</span><br><span class="line">            System.out.println(<span class="string">"row Name:"</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getQualifierArray(),cell.getQualifierOffset(), cell.getQualifierLength()))+<span class="string">" "</span>);</span><br><span class="line">            System.out.println(<span class="string">"value:"</span>+<span class="keyword">new</span> String(Bytes.toString(cell.getValueArray(),cell.getValueOffset(), cell.getValueLength()))+<span class="string">" "</span>);           </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>(4)modifyData(String tableName, String row, String column)<br>修改表tableName，行row（可以用学生姓名S_Name表示），列column指定的单元格的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">modifyData</span><span class="params">(String tableName,String row,String column,String val)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">    init();</span><br><span class="line">    Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">    Put put = <span class="keyword">new</span> Put(row.getBytes());</span><br><span class="line">    put.addColumn(column.getBytes(),<span class="keyword">null</span>,val.getBytes());</span><br><span class="line">    table.put(put);</span><br><span class="line">    table.close();</span><br><span class="line">    close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(5)deleteRow(String tableName, String row)<br>删除表tableName中row指定的行的记录。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteRow</span><span class="params">(String tableName,String row)</span><span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        init();</span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line">        Delete delete = <span class="keyword">new</span> Delete(row.getBytes());        </span><br><span class="line">        table.delete(delete);</span><br><span class="line">        table.close();</span><br><span class="line">        close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/10/15/大数据-HBase实验以及讲解/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="大数据-Hbase实验以及讲解">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-林子雨大数据-hdfs常用的操作（实验操作详细记录与讲解）" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/11/林子雨大数据-hdfs常用的操作（实验操作详细记录与讲解）/" class="article-date">
  	<time datetime="2020-10-11T03:16:21.790Z" itemprop="datePublished">2020-10-11</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/11/林子雨大数据-hdfs常用的操作（实验操作详细记录与讲解）/">
        林子雨大数据-hdfs常用的操作（实验操作详细记录与讲解）
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一、向HDFS中上传任意文本文件，如果指定的文件在HDFS中已经存在，由用户指定是追加到原有文件末尾还是覆盖原有的文件；-用JAVA编程实现相同功能"><a href="#一、向HDFS中上传任意文本文件，如果指定的文件在HDFS中已经存在，由用户指定是追加到原有文件末尾还是覆盖原有的文件；-用JAVA编程实现相同功能" class="headerlink" title="一、向HDFS中上传任意文本文件，如果指定的文件在HDFS中已经存在，由用户指定是追加到原有文件末尾还是覆盖原有的文件；(用JAVA编程实现相同功能)"></a>一、向HDFS中上传任意文本文件，如果指定的文件在HDFS中已经存在，由用户指定是追加到原有文件末尾还是覆盖原有的文件；(用JAVA编程实现相同功能)</h2><ul>
<li>shell命令<br>1.首先，在我本地目录下创建一个本地文件local.txt<br>我的文件路径是 <em>/usr/local/hadoop/input$</em> </li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim local.txt</span><br></pre></td></tr></table></figure>
<p>2.检查要追加的原有文件是否已经存在</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//检查操作</span><br><span class="line">$./bin/hdfs dfs -<span class="built_in">test</span> -e text.txt</span><br><span class="line">//输出检查后的结果 1 表示不存在 0 表示存在</span><br><span class="line"><span class="built_in">echo</span> $?</span><br></pre></td></tr></table></figure>
<p>3.指定是进行追加还是覆盖操作</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">不存在我们就执行复制操作</span><br><span class="line">./bin/hdfs dfs -copyFromLocal -f ./input/local.txt test.txt</span><br><span class="line">存在我们就执行追加操作</span><br><span class="line">./bin/hdfs dfs -appendToFile ./input/local.txt text.txt</span><br></pre></td></tr></table></figure>
<p>下面我们把上面的语句整合一下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> $(./bin/hdfs dfs -<span class="built_in">test</span> -e test.txt);</span><br><span class="line">&gt; <span class="keyword">then</span> $(./bin/hdfs dfs -copyFromLocal -f ./input/local.txt test.txt);</span><br><span class="line">&gt; <span class="keyword">else</span> $(./bin/hdfs dfs -appendToFile ./input/local.txt test.txt);</span><br><span class="line">&gt; <span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<ul>
<li>java编程</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test1;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyFromLocalHost</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">test</span><span class="params">(Configuration conf, String path)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> Path(path));</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 复制文件到指定路径</span></span><br><span class="line"><span class="comment">     * 若路径已存在，则进行覆盖</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copyFromLocalFile</span><span class="params">(Configuration conf, String localFilePath, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path localPath = <span class="keyword">new</span> Path(localFilePath);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        <span class="comment">/* fs.copyFromLocalFile 第一个参数表示是否删除源文件，第二个参数表示是否覆盖 */</span></span><br><span class="line">        fs.copyFromLocalFile(<span class="keyword">false</span>, <span class="keyword">true</span>, localPath, remotePath);</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 追加文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">appendToFile</span><span class="params">(Configuration conf, String localFilePath, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件读入流 */</span></span><br><span class="line">        FileInputStream in = <span class="keyword">new</span> FileInputStream(localFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件输出流，输出的内容将追加到文件末尾 */</span></span><br><span class="line">        FSDataOutputStream out = fs.append(remotePath);</span><br><span class="line">        <span class="comment">/* 读写文件内容 */</span></span><br><span class="line">        <span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">int</span> read = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (read = in.read(data)) &gt; <span class="number">0</span> ) &#123;</span><br><span class="line">            out.write(data, <span class="number">0</span>, read);</span><br><span class="line">        &#125;</span><br><span class="line">        out.close();</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        <span class="comment">//在这里输入在hdfs配置文件中配置的地址即可。</span></span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String localFilePath = <span class="string">"/usr/local/hadoop/input/local.txt"</span>;    <span class="comment">// 本地路径</span></span><br><span class="line">        <span class="comment">//这里的路径是我们之前配置的hadoop的用户目录</span></span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line">        <span class="comment">//这里选择文件是否覆盖还是追加</span></span><br><span class="line">        String choice = <span class="string">"append"</span>;    <span class="comment">// 若文件存在则追加到文件末尾</span></span><br><span class="line"><span class="comment">//      String choice = "overwrite";    // 若文件存在则覆盖</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/* 判断文件是否存在 */</span></span><br><span class="line">            Boolean fileExists = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">if</span> (CopyFromLocalHost.test(conf, remoteFilePath)) &#123;</span><br><span class="line">                fileExists = <span class="keyword">true</span>;</span><br><span class="line">                System.out.println(remoteFilePath + <span class="string">" 已存在."</span>);</span><br><span class="line">               <span class="comment">// choice = "overwrite";</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(remoteFilePath + <span class="string">" 不存在."</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* 进行处理 */</span></span><br><span class="line">            <span class="keyword">if</span> ( !fileExists) &#123; <span class="comment">// 文件不存在，则上传</span></span><br><span class="line">                CopyFromLocalHost.copyFromLocalFile(conf, localFilePath, remoteFilePath);</span><br><span class="line">                System.out.println(localFilePath + <span class="string">" 已上传至 "</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( choice.equals(<span class="string">"overwrite"</span>) ) &#123;    <span class="comment">// 选择覆盖</span></span><br><span class="line">                CopyFromLocalHost.copyFromLocalFile(conf, localFilePath, remoteFilePath);</span><br><span class="line">                System.out.println(localFilePath + <span class="string">" 已覆盖 "</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( choice.equals(<span class="string">"append"</span>) ) &#123;   <span class="comment">// 选择追加</span></span><br><span class="line">                CopyFromLocalHost.appendToFile(conf, localFilePath, remoteFilePath);</span><br><span class="line">                System.out.println(localFilePath + <span class="string">" 已追加至 "</span> + remoteFilePath);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为我的hd f s是搭建在阿里云上的，在云上没有安装成功Eclipse.所以就在本地编写了代码，上传到云上执行的，下面的执行了同样的过程。<br>更方便的操作，等我完全搞懂了，如何在本地执行分布式或者在云上安装好eclipse，在做记录。<br>操作成功后会显示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2020-10-10 16:33:06,050 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS</span><br><span class="line">/user/hadoop/text.txt 不存在.</span><br><span class="line">2020-10-10 16:33:08,706 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">/usr/<span class="built_in">local</span>/hadoop/local.txt 已上传至 /user/hadoop/text.txt</span><br></pre></td></tr></table></figure>
<h2 id="二、-从HDFS中下载指定文件，如果本地文件与要下载的文件名称相同，则自动对下载的文件重命名"><a href="#二、-从HDFS中下载指定文件，如果本地文件与要下载的文件名称相同，则自动对下载的文件重命名" class="headerlink" title="二、 从HDFS中下载指定文件，如果本地文件与要下载的文件名称相同，则自动对下载的文件重命名"></a>二、 从HDFS中下载指定文件，如果本地文件与要下载的文件名称相同，则自动对下载的文件重命名</h2><p>我们还是使用上面用过的local.txt 以及在h d f s中的test.txt文件。</p>
<ul>
<li>Shell编程</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> $(./bin/hdfs dfs -<span class="built_in">test</span> -e file:/usr/<span class="built_in">local</span>/hadoop/input/text.txt); </span><br><span class="line"><span class="keyword">then</span> $(./bin/hdfs dfs -copyToLocal text.txt ./input/text2.txt); </span><br><span class="line"><span class="keyword">else</span> $(./bin/hdfs dfs -copyToLocal text.txt ./input/text.txt );</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<ul>
<li>java编程</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyFromLocalHost</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 下载文件到本地</span></span><br><span class="line"><span class="comment">     * 判断本地路径是否已存在，若已存在，则自动进行重命名</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copyToLocal</span><span class="params">(Configuration conf, String remoteFilePath, String localFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        File f = <span class="keyword">new</span> File(localFilePath);</span><br><span class="line">        <span class="comment">/* 如果文件名存在，自动重命名(在文件名后面加上 _0, _1 ...) */</span></span><br><span class="line">        <span class="keyword">if</span> (f.exists()) &#123;</span><br><span class="line">            System.out.println(localFilePath + <span class="string">" 已存在."</span>);</span><br><span class="line">            Integer i = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                f = <span class="keyword">new</span> File(localFilePath + <span class="string">"_"</span> + i.toString());</span><br><span class="line">                <span class="keyword">if</span> (!f.exists()) &#123;</span><br><span class="line">                    localFilePath = localFilePath + <span class="string">"_"</span> + i.toString();</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">"将重新命名为: "</span> + localFilePath);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 下载文件到本地</span></span><br><span class="line">       Path localPath = <span class="keyword">new</span> Path(localFilePath);</span><br><span class="line">       fs.copyToLocalFile(remotePath, localPath);</span><br><span class="line">       fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String localFilePath = <span class="string">"/usr/local/hadoop/input/text.txt"</span>;    <span class="comment">// 本地路径</span></span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            CopyFromLocalHost.copyToLocal(conf, remoteFilePath, localFilePath);</span><br><span class="line">            System.out.println(<span class="string">"下载完成"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>成功执行后会显示（因为我上面已经执行过shell程序了，所以在我操作的文件夹上，内容是已经存在了的，因此进行重命名操作）</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">10</span>-<span class="number">10</span> <span class="number">18</span>:<span class="number">46</span>:<span class="number">17</span>,<span class="number">802</span> INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS</span><br><span class="line">/usr/local/hadoop/input/text.txt 已存在.</span><br><span class="line">将重新命名为: /usr/local/hadoop/input/text.txt_0</span><br><span class="line"><span class="number">2020</span>-<span class="number">10</span>-<span class="number">10</span> <span class="number">18</span>:<span class="number">46</span>:<span class="number">21</span>,<span class="number">666</span> INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">下载完成</span><br></pre></td></tr></table></figure>
<h2 id="三、将HDFS中指定文件的内容输出到终端中"><a href="#三、将HDFS中指定文件的内容输出到终端中" class="headerlink" title="三、将HDFS中指定文件的内容输出到终端中"></a>三、将HDFS中指定文件的内容输出到终端中</h2><p>本质就是查看文件内容</p>
<ul>
<li><p>Shell</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -cat text.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>java</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyFromLocalHost</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">cat</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        FSDataInputStream in = fs.open(remotePath);</span><br><span class="line">        BufferedReader d = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(in));</span><br><span class="line">        String line = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (line = d.readLine()) != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            System.out.println(line);</span><br><span class="line">        &#125;</span><br><span class="line">       d.close();</span><br><span class="line">       in.close();</span><br><span class="line">       fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"读取文件: "</span> + remoteFilePath);</span><br><span class="line">            CopyFromLocalHost.cat(conf, remoteFilePath);</span><br><span class="line">            System.out.println(<span class="string">"\n读取完成"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>读取成功后显示</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">10</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">14</span>:<span class="number">58</span>,<span class="number">684</span> INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS</span><br><span class="line">读取文件: /user/hadoop/text.txt</span><br><span class="line"><span class="number">2020</span>-<span class="number">10</span>-<span class="number">10</span> <span class="number">19</span>:<span class="number">15</span>:<span class="number">01</span>,<span class="number">401</span> INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">this  ssss</span><br><span class="line"></span><br><span class="line">读取完成</span><br></pre></td></tr></table></figure>
<h2 id="四、显示HDFS中指定的文件的读写权限、大小、创建时间、路径等信息"><a href="#四、显示HDFS中指定的文件的读写权限、大小、创建时间、路径等信息" class="headerlink" title="四、显示HDFS中指定的文件的读写权限、大小、创建时间、路径等信息"></a>四、显示HDFS中指定的文件的读写权限、大小、创建时间、路径等信息</h2><ul>
<li>shell</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -ls -h text.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyFromLocalHost</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 显示指定文件的信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">ls</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        FileStatus[] fileStatuses = fs.listStatus(remotePath);</span><br><span class="line">        <span class="keyword">for</span> (FileStatus s : fileStatuses) &#123;</span><br><span class="line">            System.out.println(<span class="string">"路径: "</span> + s.getPath().toString());</span><br><span class="line">            System.out.println(<span class="string">"权限: "</span> + s.getPermission().toString());</span><br><span class="line">            System.out.println(<span class="string">"大小: "</span> + s.getLen());</span><br><span class="line">            <span class="comment">/* 返回的是时间戳,转化为时间日期格式 */</span></span><br><span class="line">            Long timeStamp = s.getModificationTime();</span><br><span class="line">            SimpleDateFormat format =  <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</span><br><span class="line">            String date = format.format(timeStamp);  </span><br><span class="line">            System.out.println(<span class="string">"时间: "</span> + date);</span><br><span class="line">        &#125;</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"读取文件信息: "</span> + remoteFilePath);</span><br><span class="line">            CopyFromLocalHost.ls(conf, remoteFilePath);</span><br><span class="line">            System.out.println(<span class="string">"\n读取完成"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果显示</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">读取文件信息: /user/hadoop/text.txt</span><br><span class="line">路径: hdfs://0.0.0.0:8020/user/hadoop/text.txt</span><br><span class="line">权限: rw-r--r--</span><br><span class="line">大小: 11</span><br><span class="line">时间: 2020-10-10 16:33:08</span><br><span class="line"></span><br><span class="line">读取完成</span><br></pre></td></tr></table></figure>
<h2 id="五、给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息"><a href="#五、给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息" class="headerlink" title="五、给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息"></a>五、给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息</h2><ul>
<li>shell</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/hdfs dfs -ls -R -h</span><br></pre></td></tr></table></figure>
<ul>
<li>java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CopyFromLocalHost</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 显示指定文件夹下所有文件的信息（递归）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lsDir</span><span class="params">(Configuration conf, String remoteDir)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path dirPath = <span class="keyword">new</span> Path(remoteDir);</span><br><span class="line">        <span class="comment">/* 递归获取目录下的所有文件 */</span></span><br><span class="line">        RemoteIterator&lt;LocatedFileStatus&gt; remoteIterator = fs.listFiles(dirPath, <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">/* 输出每个文件的信息 */</span></span><br><span class="line">        <span class="keyword">while</span> (remoteIterator.hasNext()) &#123;</span><br><span class="line">            FileStatus s = remoteIterator.next();</span><br><span class="line">            System.out.println(<span class="string">"路径: "</span> + s.getPath().toString());</span><br><span class="line">            System.out.println(<span class="string">"权限: "</span> + s.getPermission().toString());</span><br><span class="line">            System.out.println(<span class="string">"大小: "</span> + s.getLen());</span><br><span class="line">            <span class="comment">/* 返回的是时间戳,转化为时间日期格式 */</span></span><br><span class="line">            Long timeStamp = s.getModificationTime();</span><br><span class="line">            SimpleDateFormat format =  <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</span><br><span class="line">            String date = format.format(timeStamp);  </span><br><span class="line">            System.out.println(<span class="string">"时间: "</span> + date);</span><br><span class="line">            System.out.println();</span><br><span class="line">        &#125;</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;    </span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteDir = <span class="string">"/user/hadoop"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"(递归)读取目录下所有文件的信息: "</span> + remoteDir);</span><br><span class="line">            CopyFromLocalHost.lsDir(conf, remoteDir);</span><br><span class="line">            System.out.println(<span class="string">"读取完成"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="六、提供一个HDFS内的文件的路径，对该文件进行创建和删除操作。如果文件所在目录不存在，则自动创建目录"><a href="#六、提供一个HDFS内的文件的路径，对该文件进行创建和删除操作。如果文件所在目录不存在，则自动创建目录" class="headerlink" title="六、提供一个HDFS内的文件的路径，对该文件进行创建和删除操作。如果文件所在目录不存在，则自动创建目录"></a>六、提供一个HDFS内的文件的路径，对该文件进行创建和删除操作。如果文件所在目录不存在，则自动创建目录</h2><ul>
<li>shell</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> $(hdfs dfs -test -d dir1/dir2);</span><br><span class="line">then $(hdfs dfs -touchz dir1/dir2/filename); </span><br><span class="line"><span class="keyword">else</span> $(hdfs dfs -mkdir -p dir1/dir2 &amp;&amp; hdfs dfs -touchz dir1/dir2/filename); </span><br><span class="line">fi</span><br><span class="line">hdfs dfs -rm dir1/dir2/filename   <span class="comment">#删除文件</span></span><br></pre></td></tr></table></figure>
<ul>
<li>java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">test</span><span class="params">(Configuration conf, String path)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> Path(path));</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">mkdir</span><span class="params">(Configuration conf, String remoteDir)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path dirPath = <span class="keyword">new</span> Path(remoteDir);</span><br><span class="line">        <span class="keyword">boolean</span> result = fs.mkdirs(dirPath);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">touchz</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        FSDataOutputStream outputStream = fs.create(remotePath);</span><br><span class="line">        outputStream.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">rm</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        <span class="keyword">boolean</span> result = fs.delete(remotePath, <span class="keyword">false</span>);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/input/text.txt"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line">        String remoteDir = <span class="string">"/user/hadoop/input"</span>;    <span class="comment">// HDFS路径对应的目录</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/* 判断路径是否存在，存在则删除，否则进行创建 */</span></span><br><span class="line">            <span class="keyword">if</span> ( HDFSApi.test(conf, remoteFilePath) ) &#123;</span><br><span class="line">                HDFSApi.rm(conf, remoteFilePath); <span class="comment">// 删除</span></span><br><span class="line">                System.out.println(<span class="string">"删除路径: "</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ( !HDFSApi.test(conf, remoteDir) ) &#123; <span class="comment">// 若目录不存在，则进行创建</span></span><br><span class="line">                    HDFSApi.mkdir(conf, remoteDir);</span><br><span class="line">                    System.out.println(<span class="string">"创建文件夹: "</span> + remoteDir);</span><br><span class="line">                &#125;</span><br><span class="line">                HDFSApi.touchz(conf, remoteFilePath);</span><br><span class="line">                System.out.println(<span class="string">"创建路径: "</span> + remoteFilePath);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="七、提供一个HDFS的目录的路径，对该目录进行创建和删除操作。创建目录时，如果目录文件所在目录不存在则自动创建相应目录；删除目录时，由用户指定当该目录不为空时是否还删除该目录"><a href="#七、提供一个HDFS的目录的路径，对该目录进行创建和删除操作。创建目录时，如果目录文件所在目录不存在则自动创建相应目录；删除目录时，由用户指定当该目录不为空时是否还删除该目录" class="headerlink" title="七、提供一个HDFS的目录的路径，对该目录进行创建和删除操作。创建目录时，如果目录文件所在目录不存在则自动创建相应目录；删除目录时，由用户指定当该目录不为空时是否还删除该目录"></a>七、提供一个HDFS的目录的路径，对该目录进行创建和删除操作。创建目录时，如果目录文件所在目录不存在则自动创建相应目录；删除目录时，由用户指定当该目录不为空时是否还删除该目录</h2><ul>
<li>Shell</li>
</ul>
<p>创建目录的操作<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir -p dir1/dir2</span><br></pre></td></tr></table></figure></p>
<p>删除目录的操作</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rmdir dir1/dir2</span><br></pre></td></tr></table></figure>
<p>目录不为空时候的删除操作</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm -R dir1/dir2</span><br></pre></td></tr></table></figure>
<ul>
<li>java实现</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">test</span><span class="params">(Configuration conf, String path)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> Path(path));</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断目录是否为空</span></span><br><span class="line"><span class="comment">     * true: 空，false: 非空</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isDirEmpty</span><span class="params">(Configuration conf, String remoteDir)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path dirPath = <span class="keyword">new</span> Path(remoteDir);</span><br><span class="line">        RemoteIterator&lt;LocatedFileStatus&gt; remoteIterator = fs.listFiles(dirPath, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">return</span> !remoteIterator.hasNext();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">mkdir</span><span class="params">(Configuration conf, String remoteDir)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path dirPath = <span class="keyword">new</span> Path(remoteDir);</span><br><span class="line">        <span class="keyword">boolean</span> result = fs.mkdirs(dirPath);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除目录</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">rmDir</span><span class="params">(Configuration conf, String remoteDir)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path dirPath = <span class="keyword">new</span> Path(remoteDir);</span><br><span class="line">        <span class="comment">/* 第二个参数表示是否递归删除所有文件 */</span></span><br><span class="line">        <span class="keyword">boolean</span> result = fs.delete(dirPath, <span class="keyword">true</span>);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteDir = <span class="string">"/user/hadoop/input"</span>;    <span class="comment">// HDFS目录</span></span><br><span class="line">        Boolean forceDelete = <span class="keyword">false</span>;  <span class="comment">// 是否强制删除</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/* 判断目录是否存在，不存在则创建，存在则删除 */</span></span><br><span class="line">            <span class="keyword">if</span> ( !HDFSApi.test(conf, remoteDir) ) &#123;</span><br><span class="line">                HDFSApi.mkdir(conf, remoteDir); <span class="comment">// 创建目录</span></span><br><span class="line">                System.out.println(<span class="string">"创建目录: "</span> + remoteDir);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ( HDFSApi.isDirEmpty(conf, remoteDir) || forceDelete ) &#123; <span class="comment">// 目录为空或强制删除</span></span><br><span class="line">                    HDFSApi.rmDir(conf, remoteDir);</span><br><span class="line">                    System.out.println(<span class="string">"删除目录: "</span> + remoteDir);</span><br><span class="line">                &#125; <span class="keyword">else</span>  &#123; <span class="comment">// 目录不为空</span></span><br><span class="line">                    System.out.println(<span class="string">"目录不为空，不删除: "</span> + remoteDir);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="八、向HDFS中指定的文件追加内容，由用户指定内容追加到原有文件的开头或结尾"><a href="#八、向HDFS中指定的文件追加内容，由用户指定内容追加到原有文件的开头或结尾" class="headerlink" title="八、向HDFS中指定的文件追加内容，由用户指定内容追加到原有文件的开头或结尾"></a>八、向HDFS中指定的文件追加内容，由用户指定内容追加到原有文件的开头或结尾</h2><ul>
<li>shell</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -appendToFile local.txt text.txt</span><br></pre></td></tr></table></figure>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -get text.txt</span><br><span class="line">cat text.txt &gt;&gt; local.txt</span><br><span class="line">hdfs dfs -copyFromLocal -f text.txt text.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断路径是否存在</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">test</span><span class="params">(Configuration conf, String path)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">return</span> fs.exists(<span class="keyword">new</span> Path(path));</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 追加文本内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">appendContentToFile</span><span class="params">(Configuration conf, String content, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件输出流，输出的内容将追加到文件末尾 */</span></span><br><span class="line">        FSDataOutputStream out = fs.append(remotePath);</span><br><span class="line">        out.write(content.getBytes());</span><br><span class="line">        out.close();</span><br><span class="line">        fs.close();</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 追加文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">appendToFile</span><span class="params">(Configuration conf, String localFilePath, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件读入流 */</span></span><br><span class="line">        FileInputStream in = <span class="keyword">new</span> FileInputStream(localFilePath);</span><br><span class="line">        <span class="comment">/* 创建一个文件输出流，输出的内容将追加到文件末尾 */</span></span><br><span class="line">        FSDataOutputStream out = fs.append(remotePath);</span><br><span class="line">        <span class="comment">/* 读写文件内容 */</span></span><br><span class="line">        <span class="keyword">byte</span>[] data = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">int</span> read = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (read = in.read(data)) &gt; <span class="number">0</span> ) &#123;</span><br><span class="line">            out.write(data, <span class="number">0</span>, read);</span><br><span class="line">        &#125;</span><br><span class="line">        out.close();</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 移动文件到本地</span></span><br><span class="line"><span class="comment">     * 移动后，删除源文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">moveToLocalFile</span><span class="params">(Configuration conf, String remoteFilePath, String localFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        Path localPath = <span class="keyword">new</span> Path(localFilePath);</span><br><span class="line">        fs.moveToLocalFile(remotePath, localPath);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">touchz</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        FSDataOutputStream outputStream = fs.create(remotePath);</span><br><span class="line">        outputStream.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS文件</span></span><br><span class="line">        String content = <span class="string">"新追加的内容\n"</span>;</span><br><span class="line">        String choice = <span class="string">"after"</span>;        <span class="comment">//追加到文件末尾</span></span><br><span class="line"><span class="comment">//      String choice = "before";    // 追加到文件开头</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">/* 判断文件是否存在 */</span></span><br><span class="line">            <span class="keyword">if</span> ( !HDFSApi.test(conf, remoteFilePath) ) &#123;</span><br><span class="line">                System.out.println(<span class="string">"文件不存在: "</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> ( choice.equals(<span class="string">"after"</span>) ) &#123; <span class="comment">// 追加在文件末尾</span></span><br><span class="line">                    HDFSApi.appendContentToFile(conf, content, remoteFilePath);</span><br><span class="line">                    System.out.println(<span class="string">"已追加内容到文件末尾"</span> + remoteFilePath);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> ( choice.equals(<span class="string">"before"</span>) )  &#123; <span class="comment">// 追加到文件开头</span></span><br><span class="line">                    <span class="comment">/* 没有相应的api可以直接操作，因此先把文件移动到本地*/</span></span><br><span class="line"><span class="comment">/*创建一个新的HDFS，再按顺序追加内容 */</span></span><br><span class="line">                    String localTmpPath = <span class="string">"/user/hadoop/tmp.txt"</span>;</span><br><span class="line">                    <span class="comment">// 移动到本地</span></span><br><span class="line">HDFSApi.moveToLocalFile(conf, remoteFilePath, localTmpPath);</span><br><span class="line">   <span class="comment">// 创建一个新文件</span></span><br><span class="line">                    HDFSApi.touchz(conf, remoteFilePath); </span><br><span class="line">                    <span class="comment">// 先写入新内容</span></span><br><span class="line">                    HDFSApi.appendContentToFile(conf, content, remoteFilePath);</span><br><span class="line">                    <span class="comment">// 再写入原来内容</span></span><br><span class="line">                    HDFSApi.appendToFile(conf, localTmpPath, remoteFilePath); </span><br><span class="line">                    System.out.println(<span class="string">"已追加内容到文件开头: "</span> + remoteFilePath);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="九、删除HDFS中指定的文件"><a href="#九、删除HDFS中指定的文件" class="headerlink" title="九、删除HDFS中指定的文件"></a>九、删除HDFS中指定的文件</h2><ul>
<li>shell</li>
</ul>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm text.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">rm</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        <span class="keyword">boolean</span> result = fs.delete(remotePath, <span class="keyword">false</span>);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS文件</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> ( HDFSApi.rm(conf, remoteFilePath) ) &#123;</span><br><span class="line">                System.out.println(<span class="string">"文件删除: "</span> + remoteFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">"操作失败（文件不存在或删除失败）"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="十、删除HDFS中指定的目录，由用户指定目录中如果存在文件时是否删除目录"><a href="#十、删除HDFS中指定的目录，由用户指定目录中如果存在文件时是否删除目录" class="headerlink" title="十、删除HDFS中指定的目录，由用户指定目录中如果存在文件时是否删除目录"></a>十、删除HDFS中指定的目录，由用户指定目录中如果存在文件时是否删除目录</h2><p>见第7个实验</p>
<h2 id="十一、在HDFS中，将文件从源路径移动到目的路径"><a href="#十一、在HDFS中，将文件从源路径移动到目的路径" class="headerlink" title="十一、在HDFS中，将文件从源路径移动到目的路径"></a>十一、在HDFS中，将文件从源路径移动到目的路径</h2><ul>
<li>shell</li>
</ul>
<p>text.txt 是源路径，text2.txt所在的位置是目的路径所在的位置<br><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mv text.txt text2.txt</span><br></pre></td></tr></table></figure></p>
<ul>
<li>java</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApi</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 移动文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">mv</span><span class="params">(Configuration conf, String remoteFilePath, String remoteToFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path srcPath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        Path dstPath = <span class="keyword">new</span> Path(remoteToFilePath);</span><br><span class="line">        <span class="keyword">boolean</span> result = fs.rename(srcPath, dstPath);</span><br><span class="line">        fs.close();</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"hdfs:///user/hadoop/text.txt"</span>;    <span class="comment">// 源文件HDFS路径</span></span><br><span class="line">        String remoteToFilePath = <span class="string">"hdfs:///user/hadoop/new.txt"</span>;    <span class="comment">// 目的HDFS路径</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> ( HDFSApi.mv(conf, remoteFilePath, remoteToFilePath) ) &#123;</span><br><span class="line">                System.out.println(<span class="string">"将文件 "</span> + remoteFilePath + <span class="string">" 移动到 "</span> + remoteToFilePath);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    System.out.println(<span class="string">"操作失败(源文件不存在或移动失败)"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="编程实现一个类“MyFSDataInputStream”，该类继承“org-apache-hadoop-fs-FSDataInputStream”，要求如下：实现按行读取HDFS中指定文件的方法“readLine-”，如果读到文件末尾，则返回空，否则返回文件一行的文本。查看Java帮助手册或其它资料，用“java-net-URL”和“org-apache-hadoop-fs-FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中"><a href="#编程实现一个类“MyFSDataInputStream”，该类继承“org-apache-hadoop-fs-FSDataInputStream”，要求如下：实现按行读取HDFS中指定文件的方法“readLine-”，如果读到文件末尾，则返回空，否则返回文件一行的文本。查看Java帮助手册或其它资料，用“java-net-URL”和“org-apache-hadoop-fs-FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中" class="headerlink" title="编程实现一个类“MyFSDataInputStream”，该类继承“org.apache.hadoop.fs.FSDataInputStream”，要求如下：实现按行读取HDFS中指定文件的方法“readLine()”，如果读到文件末尾，则返回空，否则返回文件一行的文本。查看Java帮助手册或其它资料，用“java.net.URL”和“org.apache.hadoop.fs.FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中"></a>编程实现一个类“MyFSDataInputStream”，该类继承“org.apache.hadoop.fs.FSDataInputStream”，要求如下：实现按行读取HDFS中指定文件的方法“readLine()”，如果读到文件末尾，则返回空，否则返回文件一行的文本。查看Java帮助手册或其它资料，用“java.net.URL”和“org.apache.hadoop.fs.FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中</h2><p>关于Java API中URL类的使用细节，可以详细阅读：</p>
<p><a href="http://www.javaweb.cc/help/JavaAPI1.6/java/net/URL.html#setURLStreamHandlerFactory%28java.net.URLStreamHandlerFactory%29" target="_blank" rel="noopener">java.net.URL</a></p>
<p>关于Hadoop中FsURLStreamHandlerFactory类的使用细节可以学习：<br><a href="http://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/fs/FsUrlStreamHandlerFactory.html" target="_blank" rel="noopener">org.apache.hadoop.fs.FsURLStreamHandlerFactory</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFSDataInputStream</span> <span class="keyword">extends</span> <span class="title">FSDataInputStream</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyFSDataInputStream</span><span class="params">(InputStream in)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(in);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 实现按行读取</span></span><br><span class="line"><span class="comment">     * 每次读入一个字符，遇到"\n"结束，返回一行内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">readline</span><span class="params">(BufferedReader br)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">char</span>[] data = <span class="keyword">new</span> <span class="keyword">char</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">int</span> read = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> off = <span class="number">0</span>; </span><br><span class="line"><span class="comment">// 循环执行时，br 每次会从上一次读取结束的位置继续读取</span></span><br><span class="line"><span class="comment">//因此该函数里，off 每次都从0开始</span></span><br><span class="line">        <span class="keyword">while</span> ( (read = br.read(data, off, <span class="number">1</span>)) != -<span class="number">1</span> ) &#123;</span><br><span class="line">            <span class="keyword">if</span> (String.valueOf(data[off]).equals(<span class="string">"\n"</span>) ) &#123;</span><br><span class="line">                off += <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            off += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> (off &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> String.valueOf(data);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取文件内容</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">cat</span><span class="params">(Configuration conf, String remoteFilePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        Path remotePath = <span class="keyword">new</span> Path(remoteFilePath);</span><br><span class="line">        FSDataInputStream in = fs.open(remotePath);</span><br><span class="line">        BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(in));</span><br><span class="line">        String line = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ( (line = MyFSDataInputStream.readline(br)) != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            System.out.println(line);</span><br><span class="line">        &#125;</span><br><span class="line">        br.close();</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    conf.set(<span class="string">"fs.default.name"</span>,<span class="string">"hdfs://0.0.0.0:8020"</span>);</span><br><span class="line">        String remoteFilePath = <span class="string">"/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS路径</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            MyFSDataInputStream.cat(conf, remoteFilePath);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="查看Java帮助手册或其它资料，用“java-net-URL”和“org-apache-hadoop-fs-FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中"><a href="#查看Java帮助手册或其它资料，用“java-net-URL”和“org-apache-hadoop-fs-FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中" class="headerlink" title="查看Java帮助手册或其它资料，用“java.net.URL”和“org.apache.hadoop.fs.FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中"></a>查看Java帮助手册或其它资料，用“java.net.URL”和“org.apache.hadoop.fs.FsURLStreamHandlerFactory”编程完成输出HDFS中指定文件的文本到终端中</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.URL;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSApi</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span>&#123;  </span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());  </span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 主函数 </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String remoteFilePath = <span class="string">"hdfs://0.0.0.0:8020/user/hadoop/text.txt"</span>;    <span class="comment">// HDFS文件</span></span><br><span class="line">        InputStream in = <span class="keyword">null</span>; </span><br><span class="line">        <span class="keyword">try</span>&#123;  </span><br><span class="line">            <span class="comment">/* 通过URL对象打开数据流，从中读取数据 */</span></span><br><span class="line">            in = <span class="keyword">new</span> URL(remoteFilePath).openStream();  </span><br><span class="line">            IOUtils.copyBytes(in,System.out,<span class="number">4096</span>,<span class="keyword">false</span>);  </span><br><span class="line">        &#125; <span class="keyword">finally</span>&#123;  </span><br><span class="line">            IOUtils.closeStream(in);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/10/11/林子雨大数据-hdfs常用的操作（实验操作详细记录与讲解）/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="林子雨大数据-hdfs常用的操作（实验操作详细记录与讲解）">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Java中的Socket" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/09/Java中的Socket/" class="article-date">
  	<time datetime="2020-10-09T12:57:55.870Z" itemprop="datePublished">2020-10-09</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/09/Java中的Socket/">
        Java中的Socket
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>java.net包中提供了两种常见的网络协议的支持：</p>
<ul>
<li>TCP：TCP传输控制协议，保证了两个应用程序之间的可靠传输通信</li>
<li>UDP：UDP是用户数据报协议，一个无链接的协议，提供了应用程序之间要发送的数据的数据包。<h2 id="Socket-的定义"><a href="#Socket-的定义" class="headerlink" title="Socket 的定义"></a>Socket 的定义</h2>套接字使用TCP提供了两台计算机之间的通信机制。</li>
</ul>
<h3 id="计算机使用套接字进行通信的过程"><a href="#计算机使用套接字进行通信的过程" class="headerlink" title="计算机使用套接字进行通信的过程"></a>计算机使用套接字进行通信的过程</h3><ol>
<li>服务器实例化一个ServerSocket对象，表示通过服务器上的端口通信</li>
<li>服务器调用ServerSocket类的accept()方法，该方法会一直等待，直到客户端连接到服务器上的给定的端口。</li>
<li>服务器正在等待的时候，一个客户端实例化一个Socket对象，指定服务器名称以及端口来请求连接。</li>
<li>Socket类的构造函数试图将客户端连接到指定的服务器和端口号。如果通信被建立，则在客户端创建一个Socket对象与服务器进行通信。</li>
<li>在服务器端，accept()方法返回服务器上的一个新的socket引用，这个socket连接到客户端的socket。</li>
<li>连接建立之后，通过使用I/O流进行通信，每一个socket都有一个输出流和一个输入流。客户端的输出流连接到服务器的输入流，客户端的输入流连接到服务器的输出流。<br><em>TCP是一个双向的通信协议，数据可以通过两个数据流在同一个时间发送。</em><h2 id="Socket方法"><a href="#Socket方法" class="headerlink" title="Socket方法"></a>Socket方法</h2>参见识 java API</li>
</ol>
<h2 id="使用Socket实现文件的传输"><a href="#使用Socket实现文件的传输" class="headerlink" title="使用Socket实现文件的传输"></a>使用Socket实现文件的传输</h2><p>Server</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> ServerSocket serverSocket;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">Server</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">		serverSocket = <span class="keyword">new</span> ServerSocket(port);</span><br><span class="line">		<span class="comment">//指定超时 以毫秒为单位</span></span><br><span class="line">		serverSocket.setSoTimeout(<span class="number">10000000</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">			System.out.println(<span class="string">"waiting for client on port..."</span>+serverSocket.getLocalPort());</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				<span class="comment">//等待新的连接</span></span><br><span class="line">				Socket server = serverSocket.accept();</span><br><span class="line">				System.out.println(<span class="string">"Just connected to "</span>+server.getRemoteSocketAddress());</span><br><span class="line">				<span class="comment">//获取输入流</span></span><br><span class="line">				DataInputStream in = <span class="keyword">new</span> DataInputStream(server.getInputStream());</span><br><span class="line">					File file = <span class="keyword">new</span> File(<span class="string">"/Users/gorge/Desktop"</span>+server.getRemoteSocketAddress()+<span class="string">".txt"</span>);</span><br><span class="line">					FileOutputStream outputStream =<span class="keyword">new</span> FileOutputStream(file);</span><br><span class="line">					<span class="keyword">byte</span> car [] = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">					<span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">					<span class="keyword">while</span> ((len=in.read(car))!=-<span class="number">1</span>) &#123;</span><br><span class="line">						outputStream.write(car, <span class="number">0</span>, len);</span><br><span class="line">					&#125;</span><br><span class="line">				   outputStream.flush();</span><br><span class="line">				<span class="comment">//System.out.println("Client say"+in.readUTF());</span></span><br><span class="line">				</span><br><span class="line">				<span class="comment">//DataOutputStream out = new DataOutputStream(server.getOutputStream());</span></span><br><span class="line">				<span class="comment">//写入数据 返回这个套接字绑定的端点的地址</span></span><br><span class="line">				<span class="comment">//out.writeUTF("Thanks you for a connecting to"+server.getLocalSocketAddress()+"good bye");</span></span><br><span class="line">				server.close();</span><br><span class="line">			&#125; <span class="keyword">catch</span> (SocketException s) &#123;</span><br><span class="line">				<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">				System.out.println(<span class="string">"socket timed out"</span>);</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			&#125;<span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">					<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">					e.printStackTrace();</span><br><span class="line">					<span class="keyword">break</span>;</span><br><span class="line">				&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">int</span> port = <span class="number">5000</span>;</span><br><span class="line">		Thread thread;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			thread = <span class="keyword">new</span> Server(port);</span><br><span class="line">			thread.start();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">			<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Client</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">在这里<span class="keyword">package</span> Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="keyword">import</span> java.net.UnknownHostException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> port ;</span><br><span class="line">    String servername;</span><br><span class="line">    Socket client;</span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="title">Client</span><span class="params">(String servername, <span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">    	<span class="keyword">this</span>.servername = servername;</span><br><span class="line">    	<span class="keyword">this</span>.port = port;</span><br><span class="line">    	<span class="keyword">try</span> &#123;</span><br><span class="line">    		System.out.println(<span class="string">"Connecting to "</span>+servername+<span class="string">"on port"</span>+port);</span><br><span class="line">			client  = <span class="keyword">new</span> Socket(servername,port);</span><br><span class="line">			System.out.println(<span class="string">"Just connect to "</span>+client.getRemoteSocketAddress());</span><br><span class="line">			<span class="comment">//输出流</span></span><br><span class="line">			OutputStream outToserver = client.getOutputStream();</span><br><span class="line">			DataOutputStream out = <span class="keyword">new</span> DataOutputStream(outToserver);</span><br><span class="line">			File file1 = <span class="keyword">new</span> File(<span class="string">"/Users/gorge/Desktop/a.txt"</span>);</span><br><span class="line">			<span class="comment">//先从本地读取一个文件</span></span><br><span class="line">			FileInputStream inputStream  = <span class="keyword">new</span> FileInputStream(file1);</span><br><span class="line">			<span class="keyword">byte</span> [] b = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">			<span class="keyword">int</span> len =<span class="number">0</span>;</span><br><span class="line">			<span class="keyword">while</span>(-<span class="number">1</span>!=(len=inputStream.read(b))) &#123;</span><br><span class="line">				out.write(b,<span class="number">0</span>,len);</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">//out.writeUTF("Hello from" +client.getLocalSocketAddress());</span></span><br><span class="line">			</span><br><span class="line">			<span class="comment">//输入流</span></span><br><span class="line">			InputStream inFromserver = client.getInputStream();</span><br><span class="line">			DataInputStream in = <span class="keyword">new</span> DataInputStream(inFromserver);</span><br><span class="line">			<span class="comment">//System.out.println("Server says:"+in.readUTF());</span></span><br><span class="line">			client.close();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (UnknownHostException e) &#123;</span><br><span class="line">			<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">			<span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Client cl = <span class="keyword">new</span> Client(<span class="string">"127.0.0.1"</span>, <span class="number">5000</span>);</span><br><span class="line">	    cl.start();</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/10/09/Java中的Socket/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="Java中的Socket">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-WebMagic框架实现对58同城就业信息的爬取" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/10/02/WebMagic框架实现对58同城就业信息的爬取/" class="article-date">
  	<time datetime="2020-10-02T03:23:05.880Z" itemprop="datePublished">2020-10-02</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/10/02/WebMagic框架实现对58同城就业信息的爬取/">
        WebMagic框架实现对58同城就业信息的爬取
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>此信息的爬取，纯属是练习使用，没有用在商业用途。</strong><br>WebMagic的设计参考了业界最优秀的爬虫Scrapy，而实现则应用了HttpClient、Jsoup等Java世界最成熟的工具。</p>
<p>WebMagic由四个组件(Downloader、PageProcessor、Scheduler、Pipeline)构成，核心代码非常简单，主要是将这些组件结合并完成多线程的任务。<br><img src="https://img-blog.csdnimg.cn/20201001204658382.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h2><p>使用webmagic需要导入的基本包：</p>
<p><strong>webmagic-core</strong><br>webmagic-core是WebMagic核心部分，只包含爬虫基本模块和基本抽取器。WebMagic-core的目标是成为网页爬虫的一个教科书般的实现。</p>
<p><strong>webmagic-extension</strong><br>webmagic-extension是WebMagic的主要扩展模块，提供一些更方便的编写爬虫的工具。包括注解格式定义爬虫、JSON、分布式等支持。</p>
<h2 id="页面分析"><a href="#页面分析" class="headerlink" title="页面分析"></a>页面分析</h2><p>假设我们现在要爬取的是城市在北京的所有的岗位招聘信息。<br>58同城的页面的设计如下：<br><img src="https://img-blog.csdnimg.cn/20201001210902543.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>从这一个界面上大家就可以很容易的找到一些想要的基本的信息，比如说岗位、公司性质、薪资情况等信息。如果你需要的信息这些就足够了，那么你只需要对这一个界面进行分析爬取就好了。我这里为了获取更完善的信息，所以就进行了进一步的分析。</p>
<p>职位详细信息的界面设置如下：<br><img src="https://img-blog.csdnimg.cn/2020100121212968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="链接分析"><a href="#链接分析" class="headerlink" title="链接分析"></a>链接分析</h2><p><strong>总体界面链接分析：</strong><br><em>第一页的链接：</em><br><a href="https://search.51job.com/list/010000,000000,0000,00,9,99,+,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=" target="_blank" rel="noopener">https://search.51job.com/list/010000,000000,0000,00,9,99,+,2,1.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=</a><br><em>第二页的链接：</em><br><a href="https://search.51job.com/list/010000,000000,0000,00,9,99,+,2,2.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=" target="_blank" rel="noopener">https://search.51job.com/list/010000,000000,0000,00,9,99,+,2,2.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=</a></p>
<p>大家对这个链接进行分析，可以发现链接是有规律的，在同一个城市下的求职信息，链接的差别主要在 <em>n.html</em> 这个位置，所以如果只是获取这个页面的信息，链接的分析到此就可以结束了，直接对页面进行详细分析，如何用xpath 进行匹配到你想要获取的信息，就可以了。</p>
<p><strong>详细页面链接分析：</strong><br>第一个职位链接：<br><a href="https://jobs.51job.com/beijing-tzq/124559934.html?s=01&amp;t=0" target="_blank" rel="noopener">https://jobs.51job.com/beijing-tzq/124559934.html?s=01&amp;t=0</a><br>第二个职位链接：<br><a href="https://jobs.51job.com/beijing-cyq/117551387.html?s=01&amp;t=0" target="_blank" rel="noopener">https://jobs.51job.com/beijing-cyq/117551387.html?s=01&amp;t=0</a></p>
<p>这里我没有看出很容易处理的共同点来。所有这个链接就不能很简单的获取。但是我们可以从每一个汇总页的位置获得，大家可以多看几个链接进行分析，可以用正则表达式进行进一步的分析（这个方式似乎更方便一些）</p>
<h2 id="页面HTML分析"><a href="#页面HTML分析" class="headerlink" title="页面HTML分析"></a>页面HTML分析</h2><p>所以我们这里就直接分析总页就可以了。<br><img src="https://img-blog.csdnimg.cn/20201001212707496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>大家看到这里是不是已经很明显了，对于总页的每一个模块的链接是非常明显的，并且58同城的信息每一个模块的设置的格式是非常整洁的。可以看到每一个div的class属性是e,然后直接找子标签为a的标签的href属性就可以得到你想要的进一步的页面的链接。</p>
<p>所以，就进行了两步爬取分析。第一步是爬取相关招聘信息的网址，第二步是针对当前网址爬取招聘岗位的详细信息。</p>
<h2 id="编写爬虫（这里只介绍一下爬取网址，详细信息过程一样）"><a href="#编写爬虫（这里只介绍一下爬取网址，详细信息过程一样）" class="headerlink" title="编写爬虫（这里只介绍一下爬取网址，详细信息过程一样）"></a>编写爬虫（这里只介绍一下爬取网址，详细信息过程一样）</h2><ul>
<li>在WebMagic里面如果想要实现基本的爬虫，只需要编写一个类实现Pa geProcessor即可，需要重写process(Page page)方法</li>
<li>爬虫的配置<br>1、Spider<br>Spider是爬虫启动的入口。在启动爬虫之前，我们需要使用一个PageProcessor创建一个Spider对象，然后使用run()进行启动。同时Spider的其他组件（Downloader、Scheduler、Pipeline）都可以通过set方法来进行设置。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Spider.create(<span class="keyword">new</span> URls())</span><br><span class="line">                .addUrl(<span class="string">"url"</span>)</span><br><span class="line"><span class="comment">//使用文件保存抓取URL，可以在关闭程序并下次启动时，从之前抓取到的URL继续抓取(具体内容查看Scheduler的配置)</span></span><br><span class="line">                .setScheduler(<span class="keyword">new</span> FileCacheQueueScheduler(<span class="string">"./51jobUrl"</span>))</span><br><span class="line">                .thread(<span class="number">5</span>)</span><br><span class="line">                .run();</span><br></pre></td></tr></table></figure>
<p>  2、Site<br>对站点本身的一些配置信息，例如编码、HTTP头、超时时间、重试策略等、代理等，都可以通过设置Site对象来进行配置。<br>private Site site = Site.me().setRetryTimes(3).setSleepTime(10000).setTimeOut(10000);</p>
<ul>
<li>抽取信息并且将信息保留下来</li>
</ul>
<p>将获取到的页面进行xpath解析，xpath技术这里就不在赘述。.all（）方法是返回所有抽取结果。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">page.getHtml().xpath(<span class="string">"//div[@class='el']//p[@class='t1']/span/a/@href"</span>).all()</span><br></pre></td></tr></table></figure></p>
<p>将获得数据保存下来</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">page.putField(<span class="string">"url"</span>,page.getHtml().xpath(<span class="string">"//div[@class='el']//p[@class='t1']/span/a/@href"</span>).all());</span><br></pre></td></tr></table></figure>
<p>因为我们这里需要将数据保存到数据库中，因此需要将数据从f ield中通过名称获取出来</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String  a = page.getResultItems().get(<span class="string">"url"</span>).toString();</span><br></pre></td></tr></table></figure>
<ul>
<li>从页面发现后续的地址来进行抓取<br>list是你要进行匹配的链接，可以是使用正则表达式进行匹配的，也可以是手动添加的等。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">page.addTargetRequests(list);</span><br></pre></td></tr></table></figure>
<ul>
<li>数据已经获得了，最后将这些数据插入到提前建设好的数据库就可以了。</li>
<li><a href="https://github.com/CattleZ/MacLearngit/tree/master/WebMagic" target="_blank" rel="noopener">源码</a><br><a href="https://webmagic.io/docs/zh/" target="_blank" rel="noopener">官方学习文档</a></li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/10/02/WebMagic框架实现对58同城就业信息的爬取/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="WebMagic框架实现对58同城就业信息的爬取">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-本机Mac建设Git记录" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/09/19/本机Mac建设Git记录/" class="article-date">
  	<time datetime="2020-09-19T08:04:42.150Z" itemprop="datePublished">2020-09-19</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/09/19/本机Mac建设Git记录/">
        本机Mac建设git记录《一》
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>首先，是在电脑上通过app store 安装Xcode.<br>在 Xcode中找到locations 这个 选项，可以发现有一个Command Line Tools 的工具。</p>
<h2 id="创建本地仓库"><a href="#创建本地仓库" class="headerlink" title="创建本地仓库"></a>创建本地仓库</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir learngit</span><br><span class="line">git init</span><br></pre></td></tr></table></figure>
<p>我的这个安装目录是 /Users/gorge/learngit</p>
<h2 id="查看git是否配置成功"><a href="#查看git是否配置成功" class="headerlink" title="查看git是否配置成功"></a>查看git是否配置成功</h2><p>git config –list</p>
<h2 id="密钥的位置"><a href="#密钥的位置" class="headerlink" title="密钥的位置"></a>密钥的位置</h2><p>在gorge 下执行ls -al 查看是否存在 .ssh 目录</p>
<h2 id="上传方式"><a href="#上传方式" class="headerlink" title="上传方式"></a>上传方式</h2><ul>
<li>首先我们要将我们要进行管理的文件 移动到本地建立的文件夹</li>
<li>在当前目录执行 <strong>git add [文件名]</strong> 将文件添加到本地仓库</li>
<li>执行提交 <strong>git commit -m</strong> “文件描述” 命令 ，告诉系统文件提交到仓库</li>
<li>将文件 直接提交到 远程仓库的命令是 <strong>git push origin master</strong> 命令进行提交</li>
</ul>
<p>本地文件夹是<strong>工作区</strong>，<em>.git</em>目录是<strong>版本库</strong><br>我们执行的添加操作实际上是指将信息添加到本地的工作区中的版本库中。<br><em>git add 操作将数据添加到暂存区。</em><br><em>git commit 操作提交更改，将内容添加到分支master</em></p>
<h2 id="查看历史修改版本的命令"><a href="#查看历史修改版本的命令" class="headerlink" title="查看历史修改版本的命令"></a>查看历史修改版本的命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard  HEAD^</span><br></pre></td></tr></table></figure>
<ul>
<li>HEAD 表示当前版本</li>
<li>^ 表示回退一个版本</li>
<li>^^ 表示回退两个版本</li>
<li>如果是多个版本的话可以是 HEAD~n</li>
</ul>
<p>或者执行git reset –hard  [id]</p>
<h2 id="查看历史记录"><a href="#查看历史记录" class="headerlink" title="查看历史记录"></a>查看历史记录</h2><p>git log 用来查看提交记录<br>git reflog  用来查看你的每一次操作记录</p>
<h2 id="撤销修改"><a href="#撤销修改" class="headerlink" title="撤销修改"></a>撤销修改</h2><h3 id="主要分为两种情况："><a href="#主要分为两种情况：" class="headerlink" title="主要分为两种情况："></a>主要分为两种情况：</h3><ol>
<li>首先是在工作区的修改还没有提交到暂存区</li>
</ol>
<p>下面的命令会将文件的版本恢复为我们提交到分支的最新的版本。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- readme.txt</span><br></pre></td></tr></table></figure></p>
<ol start="3">
<li>在工作区进行了修改并且已经提交到暂存区</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD &lt;file&gt;</span><br></pre></td></tr></table></figure>
<h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><p>为了提高操作的安全行，我们在操作的过程中可以使用<br>创建新的分支–执行操作<code></code>–合并分支 的过程。<br>我们通常使用的是一个分支master分支。但是对于git来说，分支的创建与合并是非常快速的。因此，我们为了操作的安全性，创建一个新的分支进行操作无疑是一个非常好的方法。</p>
<p>执行创建分支<em>dev</em>，并且将当前工作转换到当前分支上面。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b dev</span><br></pre></td></tr></table></figure></p>
<p>查看当前分支</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure>
<p>在当前分支执行操作完成后，进行添加并提交</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git add &lt;文件名&gt;</span><br><span class="line">git commit -m <span class="string">"文件描述"</span></span><br></pre></td></tr></table></figure>
<p>分支的切换操作,master是我们的默认分支</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout master</span><br></pre></td></tr></table></figure>
<p>或者<br>创建并且切换到新的分支<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git switch -c dev</span><br><span class="line">//切换到已有分支</span><br><span class="line">git switch master</span><br></pre></td></tr></table></figure></p>
<p>将dev分支进行合并</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge dev</span><br></pre></td></tr></table></figure>
<p>合并完成之后，新创建的分支就可以删除了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d dev</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/09/19/本机Mac建设Git记录/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="本机Mac建设git记录《一》">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Normalized Discounted Cumulative Gain(NDCG)" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/07/12/Normalized Discounted Cumulative Gain(NDCG)/" class="article-date">
  	<time datetime="2020-07-12T08:33:05.548Z" itemprop="datePublished">2020-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/07/12/Normalized Discounted Cumulative Gain(NDCG)/">
        NDCG
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>归一化则损累积增益<br>这个指标通常是用来衡量和评价搜索结果算法</p>
<ol>
<li>高关联度的结果比一般关联度的结果更影响最终的指标得分</li>
<li>有高关联度的结果出现在更靠前的位置的时候，指标会越高<h2 id="累计增益CG"><a href="#累计增益CG" class="headerlink" title="累计增益CG"></a>累计增益CG</h2></li>
</ol>
<p>一个搜索结果相关性分数的总和，与顺序无关<br>指定位置P的CG为：<br><img src="https://img-blog.csdnimg.cn/20200709095732954.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其中reli 表示 i这个位置上的相关度。</p>
<h2 id="折损累计增益DCG"><a href="#折损累计增益DCG" class="headerlink" title="折损累计增益DCG"></a>折损累计增益DCG</h2><p>就是在每一个CG的结果上除以一个折损值，DCG在每个项目的得分乘上一个权值，该权值与位置成反关系，即位置越靠前，权值越大，目的是为了让排名越靠前的结果越能影响最后的结果。排序越往后，价值越低。<br><img src="https://img-blog.csdnimg.cn/20200709100512191.png" alt="在这里插入图片描述"><br>或者<br><img src="https://img-blog.csdnimg.cn/20200709100721635.png" alt="在这里插入图片描述"></p>
<h2 id="归一化则损累计增益"><a href="#归一化则损累计增益" class="headerlink" title="归一化则损累计增益"></a>归一化则损累计增益</h2><p>由于搜索结果随着检索词的不同，返回的数量是不一致的。而DCG是一个累加的值，没法对两个不同的结果进行比较，所以需要进行一个归一化的处理。<br><img src="https://img-blog.csdnimg.cn/20200709101206431.png" alt="在这里插入图片描述"><br>IDCG 为理想情况下的最大的DCG值<br><img src="https://img-blog.csdnimg.cn/20200709101246215.png" alt="在这里插入图片描述"><br>其中|REL|表示结果按照相关性从大到小的顺序排序，取前P个结果组成的集合。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/07/12/Normalized Discounted Cumulative Gain(NDCG)/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="NDCG">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Pearson Correlation" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/07/12/Pearson Correlation/" class="article-date">
  	<time datetime="2020-07-12T08:33:05.539Z" itemprop="datePublished">2020-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/07/12/Pearson Correlation/">
        Pearson Collelation
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>皮尔森相关系数是衡量线性关联性的程度，P的一个几何解释是其代表两个变量的取值根据均值集中后构成的向量之间夹角的余弦。</p>
<ul>
<li>0 无相关</li>
<li>0-1 正相关</li>
<li>-1 - 0负相关</li>
</ul>
<h2 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h2><ul>
<li>0.8-1.0 极强相关</li>
<li>0.6-0.8 强相关</li>
<li>0.4-0.6 中等相关</li>
<li>0.2- 0.4 弱相关</li>
<li><p>0.0- 0.2 极弱相关或者无关</p>
<h2 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h2></li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200709092607634.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTM2NzE2,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>两个连续变量（x，y）的per 系数P（x,y）等于他们之间的协方差cov（x,y）除以他们各自的标准差成绩。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line">vec1 = [0,1,2,3,4]</span><br><span class="line">vec2 = [0,1,2,3,4]</span><br><span class="line">def pearson(vec1,vec2):</span><br><span class="line">    n = len(vec1)</span><br><span class="line">    n1= len(vec2)</span><br><span class="line">    if(n==n1):</span><br><span class="line">        sum1 = sum(float(vec1[i]) for i in range(n))</span><br><span class="line">        sum2 = sum(float(vec2[i]) for i in range(n))</span><br><span class="line">        sum1_pow = sum([pow(v,2.0) for v in vec1])</span><br><span class="line">        sum2_pow = sum([pow(v,2.0) for v in vec2])</span><br><span class="line">        p_sum = sum([vec1[i]*vec2[i] for i in range(n)])</span><br><span class="line">        num = p_sum-(sum1*sum2/n)</span><br><span class="line">        fen = math.sqrt((sum1_pow-pow(sum1,2)/n)*(sum2_pow-pow(sum2,2)/n))</span><br><span class="line">        if fen ==0:</span><br><span class="line">            return 0.0;</span><br><span class="line">        return num/fen;</span><br><span class="line">    return 0.0;</span><br><span class="line">v = pearson(vec1,vec2);</span><br><span class="line">print(v)</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/07/12/Pearson Correlation/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="Pearson Collelation">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-PDF &amp; CDF" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/07/12/PDF & CDF/" class="article-date">
  	<time datetime="2020-07-12T08:33:03.643Z" itemprop="datePublished">2020-07-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/07/12/PDF & CDF/">
        PDF &amp; CDF
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="概率密度函数-PDF"><a href="#概率密度函数-PDF" class="headerlink" title="概率密度函数 PDF"></a>概率密度函数 PDF</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>在数学中，连续型随机变量的概率密度函数（在不至于混淆时可以简称为密度函数）是一个描述这个随机变量的输出值，在某个确定的取值点附近的可能性的函数。而随机变量的取值落在某个区域之内的概率则为概率密度函数在这个区域上的积分。</p>
<h2 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h2><p>对于一维连续随机变量<br>随机数据的概率密度函数：表示瞬时幅值落在指定的范围内的概率，因此是幅值的函数。它随所取范围的幅值而变化。<br>密度函数f(x) 具有以下性质：</p>
<ol>
<li>f(x) &gt;= 0</li>
<li><img src="https://img-blog.csdnimg.cn/20200709195504798.png" alt="在这里插入图片描述"><ol start="3">
<li><img src="https://img-blog.csdnimg.cn/20200709195610934.png" alt="在这里插入图片描述"></li>
</ol>
</li>
</ol>
<h1 id="累积分布函数CDF"><a href="#累积分布函数CDF" class="headerlink" title="累积分布函数CDF"></a>累积分布函数CDF</h1><p>累积分布函数又叫分布函数是概率密度函数的积分，能完整的描述一个实随机变量X的概率分布。</p>
<h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>对于所有的实数x累积分布函数<br><img src="https://img-blog.csdnimg.cn/20200709191556745.png" alt="在这里插入图片描述"></p>
<h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>对离散变量而言，所有小于等于a的值出现概率的和</p>
<h2 id="性质-1"><a href="#性质-1" class="headerlink" title="性质"></a>性质</h2><ul>
<li>有界性<br><img src="https://img-blog.csdnimg.cn/20200709191806520.png" alt="在这里插入图片描述"></li>
<li>单调性<br><img src="https://img-blog.csdnimg.cn/20200709192007587.png" alt="在这里插入图片描述"></li>
<li>右连续性<br><img src="https://img-blog.csdnimg.cn/20200709192244162.png" alt="在这里插入图片描述"><h2 id="两种应用"><a href="#两种应用" class="headerlink" title="两种应用"></a>两种应用</h2>一种是对小于参考值的现象值的出现频率的分析的累积频率分析<br>另一种是对累计分布函数进行估计，随后可以求的简单的统计值或进行各种统计假设检验。</li>
</ul>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
        
<div class="counter-tag counter">
    <span id="/2020/07/12/PDF & CDF/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="PDF &amp; CDF">
         &nbsp;
        view
    </span>
</div>

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2021 Gorge
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>